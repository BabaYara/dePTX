//
// Generated by NVIDIA NVVM Compiler
// Compiler built on Thu Jul 18 02:37:37 2013 (1374107857)
// Cuda compilation tools, release 5.5, V5.5.0
//

.version 3.2
.target sm_35
.address_size 64


.extern .func  (.param .b32 func_retval0) cudaLaunchDevice
(
  .param .b64 cudaLaunchDevice_param_0,
  .param .b64 cudaLaunchDevice_param_1,
  .param .align 4 .b8 cudaLaunchDevice_param_2[12],
  .param .align 4 .b8 cudaLaunchDevice_param_3[12],
  .param .b32 cudaLaunchDevice_param_4,
  .param .b64 cudaLaunchDevice_param_5
);


.extern .func  (.param .b64 func_retval0) cudaGetParameterBuffer
(
	.param .b64 cudaGetParameterBuffer_param_0,
	.param .b64 cudaGetParameterBuffer_param_1
)
;
.extern .func  (.param .b32 func_retval0) cudaDeviceSynchronize
(

)
;
.global .align 128 .b8 static_210_plane[256] = {0, 0, 0, 0, 0, 0, 0, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
.global .align 128 .b8 static_211_spheres[768] = {0, 0, 0, 192, 0, 0, 0, 0, 0, 0, 96, 192, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 191, 0, 0, 0, 0, 0, 0, 64, 192, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 63, 0, 0, 0, 0, 205, 204, 12, 192, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
.global .align 1 .b8 constDeltaForeach[32] = {0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3};
.global .align 1 .b8 constDeltaForeach3[32] = {0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7};

.visible .func ray_sphere_intersect___REFs_5B_vyIsect_5D_REFs_5B_vyRay_5D_REFs_5B_unSphere_5D_(
	.param .b64 ray_sphere_intersect___REFs_5B_vyIsect_5D_REFs_5B_vyRay_5D_REFs_5B_unSphere_5D__param_0,
	.param .b64 ray_sphere_intersect___REFs_5B_vyIsect_5D_REFs_5B_vyRay_5D_REFs_5B_unSphere_5D__param_1,
	.param .b64 ray_sphere_intersect___REFs_5B_vyIsect_5D_REFs_5B_vyRay_5D_REFs_5B_unSphere_5D__param_2,
	.param .align 1 .b8 ray_sphere_intersect___REFs_5B_vyIsect_5D_REFs_5B_vyRay_5D_REFs_5B_unSphere_5D__param_3[1]
)
{
	.reg .pred 	%p<12>;
	.reg .s16 	%rs<3>;
	.reg .s32 	%r<16>;
	.reg .f32 	%f<82>;
	.reg .s64 	%rd<5>;


	ld.param.u64 	%rd2, [ray_sphere_intersect___REFs_5B_vyIsect_5D_REFs_5B_vyRay_5D_REFs_5B_unSphere_5D__param_0];
	ld.param.u64 	%rd3, [ray_sphere_intersect___REFs_5B_vyIsect_5D_REFs_5B_vyRay_5D_REFs_5B_unSphere_5D__param_1];
	ld.param.u64 	%rd4, [ray_sphere_intersect___REFs_5B_vyIsect_5D_REFs_5B_vyRay_5D_REFs_5B_unSphere_5D__param_2];
	ld.v4.f32 	{%f22, %f23, %f24, %f25}, [%rd4];
	ld.f32 	%f26, [%rd4+128];
	mul.f32 	%f27, %f26, %f26;
	ld.f32 	%f10, [%rd3+20];
	ld.f32 	%f6, [%rd3+8];
	ld.f32 	%f11, [%rd3+12];
	ld.f32 	%f9, [%rd3+16];
	ld.f32 	%f5, [%rd3+4];
	ld.f32 	%f7, [%rd3];
	sub.f32 	%f28, %f7, %f22;
	sub.f32 	%f29, %f5, %f23;
	mul.f32 	%f30, %f9, %f29;
	fma.rn.f32 	%f31, %f11, %f28, %f30;
	sub.f32 	%f32, %f6, %f24;
	fma.rn.f32 	%f12, %f10, %f32, %f31;
	mul.f32 	%f33, %f29, %f29;
	fma.rn.f32 	%f34, %f28, %f28, %f33;
	fma.rn.f32 	%f35, %f32, %f32, %f34;
	sub.f32 	%f36, %f35, %f27;
	mul.f32 	%f37, %f12, %f12;
	sub.f32 	%f13, %f37, %f36;
	setp.gtu.f32	%p3, %f13, 0f00000000;
	ld.param.u8 	%rs1, [ray_sphere_intersect___REFs_5B_vyIsect_5D_REFs_5B_vyRay_5D_REFs_5B_unSphere_5D__param_3];
	and.b16  	%rs2, %rs1, 1;
	setp.eq.b16	%p2, %rs2, 1;
	and.pred  	%p4, %p3, %p2;
	selp.u32	%r2, 1, 0, %p4;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r2, 0; 
         vote.ballot.b32  %r1, %p1; 
      }
	// inline asm
	setp.eq.s32	%p5, %r1, 0;
	@%p5 bra 	BB0_10;

	mov.f32 	%f66, 0f00000000;
	sqrt.rn.f32 	%f67, %f13;
	sub.f32 	%f68, %f66, %f12;
	sub.f32 	%f14, %f68, %f67;
	setp.gtu.f32	%p7, %f14, 0f00000000;
	ld.u8 	%r5, [%rd2];
	ld.u8 	%r6, [%rd2+1];
	shl.b32 	%r7, %r6, 8;
	or.b32  	%r8, %r7, %r5;
	ld.u8 	%r9, [%rd2+2];
	ld.u8 	%r10, [%rd2+3];
	shl.b32 	%r11, %r10, 8;
	or.b32  	%r12, %r11, %r9;
	shl.b32 	%r13, %r12, 16;
	or.b32  	%r14, %r13, %r8;
	mov.b32 	 %f69, %r14;
	setp.ltu.f32	%p8, %f14, %f69;
	and.pred  	%p9, %p7, %p8;
	and.pred  	%p10, %p3, %p9;
	and.pred  	%p1, %p10, %p2;
	selp.u32	%r4, 1, 0, %p1;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r4, 0; 
         vote.ballot.b32  %r3, %p1; 
      }
	// inline asm
	setp.eq.s32	%p11, %r3, 0;
	@%p11 bra 	BB0_10;

	@!%p1 bra 	BB0_4;
	bra.uni 	BB0_3;

BB0_3:
	st.f32 	[%rd2], %f14;
	mov.u32 	%r15, 1;
	st.u32 	[%rd2+28], %r15;

BB0_4:
	@!%p1 bra 	BB0_6;
	bra.uni 	BB0_5;

BB0_5:
	fma.rn.f32 	%f70, %f14, %f11, %f7;
	st.f32 	[%rd2+4], %f70;
	fma.rn.f32 	%f71, %f14, %f9, %f5;
	st.f32 	[%rd2+8], %f71;
	fma.rn.f32 	%f72, %f14, %f10, %f6;
	st.f32 	[%rd2+12], %f72;

BB0_6:
	ld.f32 	%f17, [%rd2+12];
	ld.f32 	%f16, [%rd2+8];
	ld.f32 	%f15, [%rd2+4];
	@!%p1 bra 	BB0_8;
	bra.uni 	BB0_7;

BB0_7:
	sub.f32 	%f73, %f15, %f22;
	st.f32 	[%rd2+16], %f73;
	sub.f32 	%f74, %f16, %f23;
	st.f32 	[%rd2+20], %f74;
	sub.f32 	%f75, %f17, %f24;
	st.f32 	[%rd2+24], %f75;

BB0_8:
	ld.f32 	%f20, [%rd2+24];
	ld.f32 	%f18, [%rd2+16];
	ld.f32 	%f19, [%rd2+20];
	mul.f32 	%f76, %f19, %f19;
	fma.rn.f32 	%f77, %f18, %f18, %f76;
	fma.rn.f32 	%f78, %f20, %f20, %f77;
	rsqrt.approx.f32 	%f21, %f78;
	@!%p1 bra 	BB0_10;
	bra.uni 	BB0_9;

BB0_9:
	mul.f32 	%f79, %f21, %f18;
	st.f32 	[%rd2+16], %f79;
	mul.f32 	%f80, %f21, %f19;
	st.f32 	[%rd2+20], %f80;
	mul.f32 	%f81, %f21, %f20;
	st.f32 	[%rd2+24], %f81;

BB0_10:
	ret;
}

.visible .entry ao_task___UM_uniuniuniun_3C_unf_3E_(
	.param .u32 ao_task___UM_uniuniuniun_3C_unf_3E__param_0,
	.param .u32 ao_task___UM_uniuniuniun_3C_unf_3E__param_1,
	.param .u32 ao_task___UM_uniuniuniun_3C_unf_3E__param_2,
	.param .u64 ao_task___UM_uniuniuniun_3C_unf_3E__param_3
)
{
	.reg .pred 	%p<303>;
	.reg .s16 	%rs<2>;
	.reg .s32 	%r<531>;
	.reg .f32 	%f<1516>;
	.reg .s64 	%rd<26>;


	ld.param.u32 	%r190, [ao_task___UM_uniuniuniun_3C_unf_3E__param_0];
	ld.param.u32 	%r191, [ao_task___UM_uniuniuniun_3C_unf_3E__param_1];
	ld.param.u32 	%r192, [ao_task___UM_uniuniuniun_3C_unf_3E__param_2];
	ld.param.u64 	%rd2, [ao_task___UM_uniuniuniun_3C_unf_3E__param_3];
	mov.u32 	%r193, %ctaid.x;
	shl.b32 	%r1, %r193, 2;
	mov.u32 	%r2, %tid.x;
	shr.s32 	%r194, %r2, 5;
	add.s32 	%r195, %r194, %r1;
	mov.u32 	%r196, %nctaid.x;
	shl.b32 	%r197, %r196, 2;
	setp.ge.s32	%p39, %r195, %r197;
	@%p39 bra 	BB1_80;

	mov.u32 	%r3, %ctaid.y;
	mov.u32 	%r198, %nctaid.y;
	setp.ge.s32	%p40, %r3, %r198;
	@%p40 bra 	BB1_80;

	shr.u32 	%r199, %r2, 5;
	add.s32 	%r200, %r199, %r1;
	shl.b32 	%r201, %r200, 6;
	add.s32 	%r202, %r201, 64;
	min.s32 	%r4, %r202, %r190;
	shl.b32 	%r505, %r3, 2;
	add.s32 	%r203, %r505, 4;
	min.s32 	%r6, %r203, %r191;
	and.b32  	%r204, %r2, 31;
	shl.b32 	%r205, %r505, %r204;
	add.s32 	%r7, %r205, %r204;
	cvt.rn.f32.s32	%f787, %r192;
	sub.s32 	%r206, %r6, %r505;
	shr.s32 	%r207, %r206, 31;
	shr.u32 	%r208, %r207, 30;
	add.s32 	%r209, %r206, %r208;
	and.b32  	%r210, %r209, -4;
	sub.s32 	%r211, %r206, %r210;
	sub.s32 	%r8, %r6, %r211;
	sub.s32 	%r212, %r4, %r201;
	shr.s32 	%r213, %r212, 31;
	shr.u32 	%r214, %r213, 29;
	add.s32 	%r215, %r212, %r214;
	and.b32  	%r216, %r215, -8;
	sub.s32 	%r217, %r212, %r216;
	sub.s32 	%r9, %r4, %r217;
	cvt.u64.u32	%rd3, %r204;
	mov.u64 	%rd4, constDeltaForeach;
	add.s64 	%rd1, %rd4, %rd3;
	setp.ge.s32	%p41, %r505, %r6;
	rcp.rn.f32 	%f1, %f787;
	@%p41 bra 	BB1_80;

	cvt.rn.f32.s32	%f809, %r190;
	cvt.rn.f32.s32	%f810, %r191;
	shr.u32 	%r218, %r7, 24;
	shr.u32 	%r219, %r7, 8;
	and.b32  	%r220, %r219, 65280;
	or.b32  	%r221, %r220, %r218;
	shl.b32 	%r222, %r7, 24;
	shl.b32 	%r223, %r7, 8;
	and.b32  	%r224, %r223, 16711680;
	or.b32  	%r225, %r222, %r224;
	or.b32  	%r527, %r225, %r221;
	mul.f32 	%f4, %f1, %f1;
	xor.b32  	%r529, %r7, -1091571699;
	shf.l.wrap.b32 	%r528, %r7, %r7, 16;
	ld.global.u8 	%r10, [%rd1];
	mul.f32 	%f3, %f810, 0f3F000000;
	mul.f32 	%f2, %f809, 0f3F000000;
	mov.f32 	%f1490, %f811;
	mov.f32 	%f1489, %f812;
	mov.f32 	%f1488, %f813;
	mov.f32 	%f1487, %f814;
	mov.f32 	%f1486, %f815;
	mov.f32 	%f1485, %f816;
	mov.f32 	%f1514, %f817;
	mov.f32 	%f1513, %f818;
	mov.f32 	%f1512, %f819;
	mov.f32 	%f1511, %f820;
	mov.f32 	%f1510, %f821;
	mov.f32 	%f1509, %f822;
	mov.f32 	%f1508, %f823;
	mov.f32 	%f1507, %f824;
	mov.f32 	%f1506, %f825;
	mov.f32 	%f1505, %f826;
	mov.f32 	%f1504, %f827;
	mov.f32 	%f1503, %f828;
	mov.f32 	%f1502, %f829;
	mov.f32 	%f1501, %f830;
	mov.f32 	%f1500, %f831;
	mov.u32 	%r530, %r7;
	mov.u32 	%r504, %r505;

BB1_4:
	mov.u32 	%r16, %r504;
	setp.eq.s32	%p42, %r505, %r8;
	setp.lt.s32	%p43, %r8, %r6;
	and.pred  	%p44, %p43, %p42;
	add.s32 	%r22, %r16, %r10;
	setp.lt.s32	%p1, %r22, %r6;
	mov.u32 	%r517, %r201;
	@%p44 bra 	BB1_72;

	shl.b32 	%r518, %r200, 6;
	setp.ge.s32	%p45, %r518, %r9;
	@%p45 bra 	BB1_69;

	mov.u64 	%rd6, constDeltaForeach3;
	add.s64 	%rd7, %rd6, %rd3;
	shl.b32 	%r519, %r200, 6;
	ld.global.u8 	%rs1, [%rd7];

BB1_7:
	setp.lt.s32	%p46, %r192, 1;
	mov.f32 	%f1484, 0f00000000;
	@%p46 bra 	BB1_68;

	cvt.u32.u16	%r243, %rs1;
	and.b32  	%r244, %r243, 255;
	ld.global.f32 	%f834, [static_211_spheres+128];
	ld.global.v4.f32 	{%f835, %f836, %f837, %f838}, [static_211_spheres+256];
	ld.global.f32 	%f839, [static_211_spheres+384];
	ld.global.v4.f32 	{%f840, %f841, %f842, %f843}, [static_211_spheres+512];
	ld.global.f32 	%f844, [static_211_spheres+640];
	ld.global.v4.f32 	{%f845, %f846, %f847, %f848}, [static_210_plane];
	ld.global.v4.f32 	{%f852, %f853, %f854, %f855}, [static_210_plane+128];
	mul.f32 	%f856, %f846, %f853;
	fma.rn.f32 	%f857, %f845, %f852, %f856;
	fma.rn.f32 	%f137, %f847, %f854, %f857;
	mul.f32 	%f858, %f853, 0f00000000;
	fma.rn.f32 	%f859, %f852, 0f00000000, %f858;
	fma.rn.f32 	%f860, %f854, 0f00000000, %f859;
	sub.f32 	%f861, %f860, %f137;
	mov.f32 	%f1484, 0f00000000;
	sub.f32 	%f138, %f1484, %f861;
	ld.global.v4.f32 	{%f862, %f863, %f864, %f865}, [static_211_spheres];
	mul.f32 	%f866, %f841, %f841;
	fma.rn.f32 	%f867, %f840, %f840, %f866;
	fma.rn.f32 	%f868, %f842, %f842, %f867;
	mul.f32 	%f132, %f844, %f844;
	sub.f32 	%f133, %f868, %f132;
	mul.f32 	%f869, %f836, %f836;
	fma.rn.f32 	%f870, %f835, %f835, %f869;
	fma.rn.f32 	%f871, %f837, %f837, %f870;
	mul.f32 	%f92, %f839, %f839;
	sub.f32 	%f93, %f871, %f92;
	mul.f32 	%f872, %f863, %f863;
	fma.rn.f32 	%f873, %f862, %f862, %f872;
	fma.rn.f32 	%f874, %f864, %f864, %f873;
	mul.f32 	%f52, %f834, %f834;
	sub.f32 	%f53, %f874, %f52;
	add.s32 	%r245, %r519, %r244;
	cvt.rn.f32.s32	%f42, %r245;
	mov.u32 	%r506, 0;

BB1_9:
	mov.u32 	%r507, 0;
	cvt.rn.f32.s32	%f931, %r506;
	fma.rn.f32 	%f932, %f1, %f931, %f42;
	sub.f32 	%f933, %f932, %f2;
	div.rn.f32 	%f156, %f933, %f2;

BB1_10:
	mov.f32 	%f1452, 0f00000000;
	cvt.rn.f32.s32	%f1451, %r22;
	sub.f32 	%f1450, %f1452, %f864;
	sub.f32 	%f1449, %f1452, %f862;
	sub.f32 	%f1448, %f1452, %f863;
	mul.f32 	%f1447, %f156, %f156;
	mov.u32 	%r508, 0;
	cvt.rn.f32.s32	%f935, %r507;
	mov.f32 	%f1482, 0f00000000;
	fma.rn.f32 	%f937, %f1, %f935, %f1451;
	sub.f32 	%f938, %f937, %f3;
	sub.f32 	%f939, %f1482, %f938;
	div.rn.f32 	%f940, %f939, %f3;
	fma.rn.f32 	%f941, %f940, %f940, %f1447;
	add.f32 	%f942, %f941, 0f3F800000;
	rsqrt.approx.f32 	%f943, %f942;
	mul.f32 	%f176, %f943, %f940;
	mul.f32 	%f174, %f943, %f156;
	mul.f32 	%f944, %f176, %f1448;
	fma.rn.f32 	%f945, %f174, %f1449, %f944;
	mul.f32 	%f946, %f943, %f1450;
	sub.f32 	%f179, %f945, %f946;
	mul.f32 	%f947, %f179, %f179;
	sub.f32 	%f180, %f947, %f53;
	setp.gtu.f32	%p2, %f180, 0f00000000;
	selp.u32	%r248, 1, 0, %p2;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r248, 0; 
         vote.ballot.b32  %r247, %p1; 
      }
	// inline asm
	setp.eq.s32	%p47, %r247, 0;
	neg.f32 	%f178, %f943;
	mov.f32 	%f1478, 0f5BB1A2BC;
	@%p47 bra 	BB1_18;

	sqrt.rn.f32 	%f950, %f180;
	sub.f32 	%f951, %f1482, %f179;
	sub.f32 	%f181, %f951, %f950;
	setp.gtu.f32	%p48, %f181, 0f00000000;
	setp.ltu.f32	%p49, %f181, 0f5BB1A2BC;
	and.pred  	%p50, %p48, %p49;
	and.pred  	%p3, %p2, %p50;
	selp.u32	%r251, 1, 0, %p3;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r251, 0; 
         vote.ballot.b32  %r250, %p1; 
      }
	// inline asm
	setp.eq.s32	%p51, %r250, 0;
	mov.u32 	%r508, 0;
	@%p51 bra 	BB1_18;

	selp.f32	%f1478, %f181, 0f5BB1A2BC, %p3;
	selp.b32	%r508, 1, 0, %p3;
	@!%p3 bra 	BB1_14;
	bra.uni 	BB1_13;

BB1_13:
	fma.rn.f32 	%f1488, %f181, %f178, 0f00000000;
	fma.rn.f32 	%f1489, %f181, %f176, 0f00000000;
	fma.rn.f32 	%f1490, %f181, %f174, 0f00000000;

BB1_14:
	@!%p3 bra 	BB1_16;
	bra.uni 	BB1_15;

BB1_15:
	sub.f32 	%f1485, %f1488, %f864;
	sub.f32 	%f1486, %f1489, %f863;
	sub.f32 	%f1487, %f1490, %f862;

BB1_16:
	mul.f32 	%f952, %f1486, %f1486;
	fma.rn.f32 	%f953, %f1487, %f1487, %f952;
	fma.rn.f32 	%f954, %f1485, %f1485, %f953;
	rsqrt.approx.f32 	%f195, %f954;
	@!%p3 bra 	BB1_18;
	bra.uni 	BB1_17;

BB1_17:
	mul.f32 	%f1485, %f195, %f1485;
	mul.f32 	%f1486, %f195, %f1486;
	mul.f32 	%f1487, %f195, %f1487;

BB1_18:
	mov.f32 	%f1456, 0f00000000;
	sub.f32 	%f1455, %f1456, %f837;
	sub.f32 	%f1454, %f1456, %f835;
	sub.f32 	%f1453, %f1456, %f836;
	mul.f32 	%f955, %f176, %f1453;
	fma.rn.f32 	%f956, %f174, %f1454, %f955;
	fma.rn.f32 	%f206, %f178, %f1455, %f956;
	mul.f32 	%f957, %f206, %f206;
	sub.f32 	%f207, %f957, %f93;
	setp.gtu.f32	%p4, %f207, 0f00000000;
	selp.u32	%r254, 1, 0, %p4;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r254, 0; 
         vote.ballot.b32  %r253, %p1; 
      }
	// inline asm
	setp.eq.s32	%p52, %r253, 0;
	@%p52 bra 	BB1_26;

	sqrt.rn.f32 	%f959, %f207;
	sub.f32 	%f960, %f1482, %f206;
	sub.f32 	%f208, %f960, %f959;
	setp.gtu.f32	%p53, %f208, 0f00000000;
	setp.ltu.f32	%p54, %f208, %f1478;
	and.pred  	%p55, %p53, %p54;
	and.pred  	%p5, %p4, %p55;
	selp.u32	%r256, 1, 0, %p5;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r256, 0; 
         vote.ballot.b32  %r255, %p1; 
      }
	// inline asm
	setp.eq.s32	%p56, %r255, 0;
	@%p56 bra 	BB1_26;

	selp.f32	%f1478, %f208, %f1478, %p5;
	selp.b32	%r508, 1, %r508, %p5;
	@!%p5 bra 	BB1_22;
	bra.uni 	BB1_21;

BB1_21:
	fma.rn.f32 	%f1488, %f208, %f178, 0f00000000;
	fma.rn.f32 	%f1489, %f208, %f176, 0f00000000;
	fma.rn.f32 	%f1490, %f208, %f174, 0f00000000;

BB1_22:
	@!%p5 bra 	BB1_24;
	bra.uni 	BB1_23;

BB1_23:
	sub.f32 	%f1485, %f1488, %f837;
	sub.f32 	%f1486, %f1489, %f836;
	sub.f32 	%f1487, %f1490, %f835;

BB1_24:
	mul.f32 	%f961, %f1486, %f1486;
	fma.rn.f32 	%f962, %f1487, %f1487, %f961;
	fma.rn.f32 	%f963, %f1485, %f1485, %f962;
	rsqrt.approx.f32 	%f222, %f963;
	@!%p5 bra 	BB1_26;
	bra.uni 	BB1_25;

BB1_25:
	mul.f32 	%f1485, %f222, %f1485;
	mul.f32 	%f1486, %f222, %f1486;
	mul.f32 	%f1487, %f222, %f1487;

BB1_26:
	mov.f32 	%f1460, 0f00000000;
	sub.f32 	%f1459, %f1460, %f842;
	sub.f32 	%f1458, %f1460, %f840;
	sub.f32 	%f1457, %f1460, %f841;
	mul.f32 	%f964, %f176, %f1457;
	fma.rn.f32 	%f965, %f174, %f1458, %f964;
	fma.rn.f32 	%f233, %f178, %f1459, %f965;
	mul.f32 	%f966, %f233, %f233;
	sub.f32 	%f234, %f966, %f133;
	setp.gtu.f32	%p6, %f234, 0f00000000;
	selp.u32	%r258, 1, 0, %p6;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r258, 0; 
         vote.ballot.b32  %r257, %p1; 
      }
	// inline asm
	setp.eq.s32	%p57, %r257, 0;
	@%p57 bra 	BB1_34;

	sqrt.rn.f32 	%f968, %f234;
	sub.f32 	%f969, %f1482, %f233;
	sub.f32 	%f235, %f969, %f968;
	setp.gtu.f32	%p58, %f235, 0f00000000;
	setp.ltu.f32	%p59, %f235, %f1478;
	and.pred  	%p60, %p58, %p59;
	and.pred  	%p7, %p6, %p60;
	selp.u32	%r260, 1, 0, %p7;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r260, 0; 
         vote.ballot.b32  %r259, %p1; 
      }
	// inline asm
	setp.eq.s32	%p61, %r259, 0;
	@%p61 bra 	BB1_34;

	selp.f32	%f1478, %f235, %f1478, %p7;
	selp.b32	%r508, 1, %r508, %p7;
	@!%p7 bra 	BB1_30;
	bra.uni 	BB1_29;

BB1_29:
	fma.rn.f32 	%f1488, %f235, %f178, 0f00000000;
	fma.rn.f32 	%f1489, %f235, %f176, 0f00000000;
	fma.rn.f32 	%f1490, %f235, %f174, 0f00000000;

BB1_30:
	@!%p7 bra 	BB1_32;
	bra.uni 	BB1_31;

BB1_31:
	sub.f32 	%f1485, %f1488, %f842;
	sub.f32 	%f1486, %f1489, %f841;
	sub.f32 	%f1487, %f1490, %f840;

BB1_32:
	mul.f32 	%f970, %f1486, %f1486;
	fma.rn.f32 	%f971, %f1487, %f1487, %f970;
	fma.rn.f32 	%f972, %f1485, %f1485, %f971;
	rsqrt.approx.f32 	%f249, %f972;
	@!%p7 bra 	BB1_34;
	bra.uni 	BB1_33;

BB1_33:
	mul.f32 	%f1485, %f249, %f1485;
	mul.f32 	%f1486, %f249, %f1486;
	mul.f32 	%f1487, %f249, %f1487;

BB1_34:
	mul.f32 	%f973, %f176, %f853;
	fma.rn.f32 	%f974, %f174, %f852, %f973;
	fma.rn.f32 	%f260, %f178, %f854, %f974;
	mov.b32 	 %r263, %f260;
	and.b32  	%r264, %r263, 2147483647;
	mov.b32 	 %f261, %r264;
	setp.ltu.f32	%p62, %f261, 0f233877AA;
	selp.u32	%r262, 1, 0, %p62;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r262, 0; 
         vote.ballot.b32  %r261, %p1; 
      }
	// inline asm
	setp.eq.s32	%p63, %r261, 0;
	setp.ge.f32	%p64, %f261, 0f233877AA;
	or.pred  	%p65, %p63, %p64;
	@!%p65 bra 	BB1_39;
	bra.uni 	BB1_35;

BB1_35:
	selp.u32	%r266, 1, 0, %p64;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r266, 0; 
         vote.ballot.b32  %r265, %p1; 
      }
	// inline asm
	setp.eq.s32	%p66, %r265, 0;
	@%p66 bra 	BB1_39;

	div.rn.f32 	%f262, %f138, %f260;
	setp.gtu.f32	%p67, %f262, 0f00000000;
	setp.ltu.f32	%p68, %f262, %f1478;
	and.pred  	%p69, %p67, %p68;
	and.pred  	%p9, %p69, %p64;
	selp.u32	%r268, 1, 0, %p9;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r268, 0; 
         vote.ballot.b32  %r267, %p1; 
      }
	// inline asm
	setp.eq.s32	%p70, %r267, 0;
	@%p70 bra 	BB1_39;

	selp.b32	%r508, 1, %r508, %p9;
	@!%p9 bra 	BB1_39;
	bra.uni 	BB1_38;

BB1_38:
	mov.f32 	%f1487, %f852;
	mov.f32 	%f1486, %f853;
	mov.f32 	%f1485, %f854;
	fma.rn.f32 	%f1488, %f262, %f178, 0f00000000;
	fma.rn.f32 	%f1489, %f262, %f176, 0f00000000;
	fma.rn.f32 	%f1490, %f262, %f174, 0f00000000;

BB1_39:
	setp.ne.s32	%p10, %r508, 0;
	selp.u32	%r270, 1, 0, %p10;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r270, 0; 
         vote.ballot.b32  %r269, %p1; 
      }
	// inline asm
	setp.eq.s32	%p71, %r269, 0;
	@%p71 bra 	BB1_66;

	setp.gtu.f32	%p72, %f1487, 0fBF19999A;
	setp.ltu.f32	%p73, %f1487, 0f3F19999A;
	and.pred  	%p74, %p73, %p72;
	and.pred  	%p76, %p74, %p10;
	selp.u32	%r272, 1, 0, %p76;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r272, 0; 
         vote.ballot.b32  %r271, %p1; 
      }
	// inline asm
	setp.eq.s32	%p77, %r271, 0;
	setp.le.f32	%p78, %f1487, 0fBF19999A;
	setp.ge.f32	%p79, %f1487, 0f3F19999A;
	or.pred  	%p11, %p79, %p78;
	and.pred  	%p80, %p10, %p11;
	selp.u32	%r274, 1, 0, %p80;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r274, 0; 
         vote.ballot.b32  %r273, %p1; 
      }
	// inline asm
	setp.eq.s32	%p81, %r273, 0;
	selp.f32	%f1508, %f1485, %f1508, %p10;
	selp.f32	%f1507, %f1486, %f1507, %p10;
	selp.f32	%f1506, %f1487, %f1506, %p10;
	selp.f32	%f975, 0f00000000, %f1503, %p10;
	selp.f32	%f976, 0f3F800000, %f975, %p76;
	selp.f32	%f1479, %f975, %f976, %p77;
	fma.rn.f32 	%f274, %f1485, 0f38D1B717, %f1488;
	fma.rn.f32 	%f273, %f1486, 0f38D1B717, %f1489;
	fma.rn.f32 	%f272, %f1487, 0f38D1B717, %f1490;
	selp.f32	%f1481, 0f00000000, %f1505, %p10;
	selp.f32	%f1480, 0f00000000, %f1504, %p10;
	@%p81 bra 	BB1_44;

	setp.gtu.f32	%p82, %f1486, 0fBF19999A;
	setp.ltu.f32	%p83, %f1486, 0f3F19999A;
	and.pred  	%p84, %p83, %p82;
	and.pred  	%p85, %p84, %p11;
	and.pred  	%p87, %p85, %p10;
	selp.u32	%r276, 1, 0, %p87;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r276, 0; 
         vote.ballot.b32  %r275, %p1; 
      }
	// inline asm
	setp.eq.s32	%p88, %r275, 0;
	setp.le.f32	%p89, %f1486, 0fBF19999A;
	setp.ge.f32	%p90, %f1486, 0f3F19999A;
	or.pred  	%p91, %p90, %p89;
	and.pred  	%p12, %p11, %p91;
	and.pred  	%p92, %p12, %p10;
	selp.u32	%r278, 1, 0, %p92;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r278, 0; 
         vote.ballot.b32  %r277, %p1; 
      }
	// inline asm
	setp.eq.s32	%p93, %r277, 0;
	selp.f32	%f977, 0f3F800000, %f1480, %p87;
	selp.f32	%f1480, %f1480, %f977, %p88;
	@%p93 bra 	BB1_44;

	setp.gtu.f32	%p94, %f1485, 0fBF19999A;
	setp.ltu.f32	%p95, %f1485, 0f3F19999A;
	and.pred  	%p96, %p95, %p94;
	and.pred  	%p97, %p12, %p96;
	and.pred  	%p99, %p97, %p10;
	selp.u32	%r280, 1, 0, %p99;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r280, 0; 
         vote.ballot.b32  %r279, %p1; 
      }
	// inline asm
	setp.eq.s32	%p100, %r279, 0;
	setp.le.f32	%p101, %f1485, 0fBF19999A;
	setp.ge.f32	%p102, %f1485, 0f3F19999A;
	or.pred  	%p103, %p102, %p101;
	and.pred  	%p104, %p12, %p103;
	and.pred  	%p13, %p104, %p10;
	selp.u32	%r282, 1, 0, %p13;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r282, 0; 
         vote.ballot.b32  %r281, %p1; 
      }
	// inline asm
	setp.eq.s32	%p105, %r281, 0;
	selp.f32	%f978, 0f3F800000, %f1481, %p99;
	selp.f32	%f1481, %f1481, %f978, %p100;
	@%p105 bra 	BB1_44;

	selp.f32	%f1479, 0f3F800000, %f1479, %p13;

BB1_44:
	mul.f32 	%f1463, %f839, %f839;
	mul.f32 	%f1462, %f844, %f844;
	mul.f32 	%f1461, %f834, %f834;
	mov.u32 	%r509, 0;
	mul.f32 	%f980, %f1481, %f1507;
	mul.f32 	%f981, %f1480, %f1508;
	sub.f32 	%f982, %f981, %f980;
	selp.f32	%f983, %f982, %f1502, %p10;
	mul.f32 	%f984, %f1479, %f1508;
	mul.f32 	%f985, %f1481, %f1506;
	sub.f32 	%f986, %f985, %f984;
	selp.f32	%f987, %f986, %f1501, %p10;
	mul.f32 	%f988, %f987, %f987;
	fma.rn.f32 	%f989, %f983, %f983, %f988;
	mul.f32 	%f990, %f1480, %f1506;
	mul.f32 	%f991, %f1479, %f1507;
	sub.f32 	%f992, %f991, %f990;
	selp.f32	%f993, %f992, %f1500, %p10;
	fma.rn.f32 	%f994, %f993, %f993, %f989;
	rsqrt.approx.f32 	%f995, %f994;
	mul.f32 	%f996, %f995, %f987;
	selp.f32	%f1501, %f996, %f1501, %p10;
	mul.f32 	%f997, %f1508, %f1501;
	mul.f32 	%f998, %f995, %f993;
	selp.f32	%f1500, %f998, %f1500, %p10;
	mul.f32 	%f999, %f1507, %f1500;
	sub.f32 	%f1000, %f999, %f997;
	selp.f32	%f1001, %f1000, %f1479, %p10;
	mul.f32 	%f1002, %f1506, %f1500;
	mul.f32 	%f1003, %f995, %f983;
	selp.f32	%f1502, %f1003, %f1502, %p10;
	mul.f32 	%f1004, %f1508, %f1502;
	sub.f32 	%f1005, %f1004, %f1002;
	selp.f32	%f1006, %f1005, %f1480, %p10;
	mul.f32 	%f1007, %f1006, %f1006;
	fma.rn.f32 	%f1008, %f1001, %f1001, %f1007;
	mul.f32 	%f1009, %f1507, %f1502;
	mul.f32 	%f1010, %f1506, %f1501;
	sub.f32 	%f1011, %f1010, %f1009;
	selp.f32	%f1012, %f1011, %f1481, %p10;
	fma.rn.f32 	%f1013, %f1012, %f1012, %f1008;
	rsqrt.approx.f32 	%f1014, %f1013;
	mul.f32 	%f1015, %f1014, %f1012;
	selp.f32	%f1505, %f1015, %f1481, %p10;
	mul.f32 	%f1016, %f1014, %f1006;
	selp.f32	%f1504, %f1016, %f1480, %p10;
	mul.f32 	%f1017, %f1014, %f1001;
	selp.f32	%f1503, %f1017, %f1479, %p10;
	sub.f32 	%f293, %f272, %f862;
	sub.f32 	%f294, %f273, %f863;
	mul.f32 	%f1018, %f294, %f294;
	fma.rn.f32 	%f1019, %f293, %f293, %f1018;
	sub.f32 	%f295, %f274, %f864;
	fma.rn.f32 	%f1020, %f295, %f295, %f1019;
	sub.f32 	%f296, %f1020, %f1461;
	sub.f32 	%f301, %f272, %f840;
	sub.f32 	%f302, %f273, %f841;
	mul.f32 	%f1021, %f302, %f302;
	fma.rn.f32 	%f1022, %f301, %f301, %f1021;
	sub.f32 	%f303, %f274, %f842;
	fma.rn.f32 	%f1023, %f303, %f303, %f1022;
	sub.f32 	%f304, %f1023, %f1462;
	sub.f32 	%f297, %f272, %f835;
	sub.f32 	%f298, %f273, %f836;
	mul.f32 	%f1024, %f298, %f298;
	fma.rn.f32 	%f1025, %f297, %f297, %f1024;
	sub.f32 	%f299, %f274, %f837;
	fma.rn.f32 	%f1026, %f299, %f299, %f1025;
	sub.f32 	%f300, %f1026, %f1463;
	mul.f32 	%f1027, %f273, %f853;
	fma.rn.f32 	%f1028, %f272, %f852, %f1027;
	fma.rn.f32 	%f1029, %f274, %f854, %f1028;
	sub.f32 	%f1030, %f1029, %f137;
	sub.f32 	%f305, %f1482, %f1030;

BB1_45:
	mov.u32 	%r510, 0;

BB1_46:
	@!%p10 bra 	BB1_48;
	bra.uni 	BB1_47;

BB1_47:
	shl.b32 	%r285, %r530, 18;
	and.b32  	%r286, %r285, -524288;
	shl.b32 	%r287, %r530, 6;
	xor.b32  	%r288, %r287, %r530;
	shr.u32 	%r289, %r288, 13;
	shl.b32 	%r290, %r529, 2;
	and.b32  	%r291, %r290, -32;
	xor.b32  	%r292, %r290, %r529;
	shr.u32 	%r293, %r292, 27;
	shl.b32 	%r294, %r528, 7;
	and.b32  	%r295, %r294, -2048;
	shl.b32 	%r296, %r528, 13;
	xor.b32  	%r297, %r296, %r528;
	shr.u32 	%r298, %r297, 21;
	shl.b32 	%r299, %r527, 13;
	and.b32  	%r300, %r299, -1048576;
	shl.b32 	%r301, %r527, 3;
	xor.b32  	%r302, %r301, %r527;
	shr.u32 	%r303, %r302, 12;
	or.b32  	%r527, %r303, %r300;
	or.b32  	%r528, %r298, %r295;
	or.b32  	%r529, %r293, %r291;
	or.b32  	%r530, %r289, %r286;

BB1_48:
	xor.b32  	%r304, %r530, %r529;
	xor.b32  	%r305, %r304, %r528;
	xor.b32  	%r306, %r305, %r527;
	and.b32  	%r307, %r306, 8388607;
	or.b32  	%r308, %r307, 1065353216;
	mov.b32 	 %f1031, %r308;
	add.f32 	%f1032, %f1031, 0fBF800000;
	sqrt.rn.f32 	%f309, %f1032;
	@!%p10 bra 	BB1_50;
	bra.uni 	BB1_49;

BB1_49:
	shl.b32 	%r309, %r530, 18;
	and.b32  	%r310, %r309, -524288;
	shl.b32 	%r311, %r530, 6;
	xor.b32  	%r312, %r311, %r530;
	shr.u32 	%r313, %r312, 13;
	shl.b32 	%r314, %r529, 2;
	and.b32  	%r315, %r314, -32;
	xor.b32  	%r316, %r314, %r529;
	shr.u32 	%r317, %r316, 27;
	shl.b32 	%r318, %r528, 7;
	and.b32  	%r319, %r318, -2048;
	shl.b32 	%r320, %r528, 13;
	xor.b32  	%r321, %r320, %r528;
	shr.u32 	%r322, %r321, 21;
	shl.b32 	%r323, %r527, 13;
	and.b32  	%r324, %r323, -1048576;
	shl.b32 	%r325, %r527, 3;
	xor.b32  	%r326, %r325, %r527;
	shr.u32 	%r327, %r326, 12;
	or.b32  	%r527, %r327, %r324;
	or.b32  	%r528, %r322, %r319;
	or.b32  	%r529, %r317, %r315;
	or.b32  	%r530, %r313, %r310;

BB1_50:
	mov.f32 	%f1034, 0f3F800000;
	mov.f32 	%f1035, 0f00000000;
	mul.f32 	%f1036, %f309, %f309;
	sub.f32 	%f1037, %f1034, %f1036;
	sqrt.rn.f32 	%f1038, %f1037;
	xor.b32  	%r331, %r530, %r529;
	xor.b32  	%r332, %r331, %r528;
	xor.b32  	%r333, %r332, %r527;
	and.b32  	%r334, %r333, 8388607;
	or.b32  	%r335, %r334, 1065353216;
	mov.b32 	 %f1039, %r335;
	add.f32 	%f1040, %f1039, 0fBF800000;
	mul.f32 	%f1041, %f1040, 0f40C90FDB;
	mul.f32 	%f1042, %f1041, 0f3F22F983;
	mov.b32 	 %r336, %f1042;
	and.b32  	%r337, %r336, -2147483648;
	xor.b32  	%r338, %r336, %r337;
	mov.b32 	 %f1043, %r338;
	add.f32 	%f1044, %f1043, 0f4B000000;
	add.f32 	%f1045, %f1044, 0fCB000000;
	mov.b32 	 %r339, %f1045;
	xor.b32  	%r340, %r339, %r337;
	mov.b32 	 %f1046, %r340;
	selp.u32	%r341, 1, 0, %p107;
	and.b32  	%r342, %r341, -1082130432;
	mov.b32 	 %f1047, %r342;
	add.f32 	%f1048, %f1046, %f1047;
	cvt.rzi.s32.f32	%r343, %f1048;
	and.b32  	%r344, %r343, 3;
	setp.eq.s32	%p108, %r344, 2;
	setp.eq.s32	%p109, %r344, 0;
	or.pred  	%p110, %p109, %p108;
	selp.f32	%f1049, 0f37CFAB9C, 0f363938A8, %p110;
	selp.f32	%f1050, 0fB48B634D, 0fB2D70013, %p110;
	fma.rn.f32 	%f1051, %f1048, 0fBFC90FDB, %f1041;
	mul.f32 	%f1052, %f1051, %f1051;
	fma.rn.f32 	%f1053, %f1052, %f1050, %f1049;
	selp.f32	%f1054, 0fBAB60981, 0fB9501096, %p110;
	fma.rn.f32 	%f1055, %f1052, %f1053, %f1054;
	selp.f32	%f1056, 0f3D2AAAA4, 0f3C088898, %p110;
	fma.rn.f32 	%f1057, %f1052, %f1055, %f1056;
	selp.f32	%f1058, 0fBF000000, 0fBE2AAAAB, %p110;
	fma.rn.f32 	%f1059, %f1052, %f1057, %f1058;
	fma.rn.f32 	%f1060, %f1052, %f1059, 0f3F800000;
	selp.f32	%f1061, 0f3F800000, %f1051, %p110;
	mul.f32 	%f1062, %f1061, %f1060;
	sub.f32 	%f1063, %f1035, %f1062;
	setp.eq.s32	%p111, %r344, 1;
	or.pred  	%p112, %p111, %p108;
	selp.f32	%f1064, %f1063, %f1062, %p112;
	mul.f32 	%f1065, %f309, %f1064;
	setp.eq.s32	%p113, %r344, 3;
	or.pred  	%p114, %p111, %p113;
	selp.f32	%f1066, 0f37CFAB9C, 0f363938A8, %p114;
	selp.f32	%f1067, 0fB48B634D, 0fB2D70013, %p114;
	fma.rn.f32 	%f1068, %f1052, %f1067, %f1066;
	selp.f32	%f1069, 0fBAB60981, 0fB9501096, %p114;
	fma.rn.f32 	%f1070, %f1052, %f1068, %f1069;
	selp.f32	%f1071, 0f3D2AAAA4, 0f3C088898, %p114;
	fma.rn.f32 	%f1072, %f1052, %f1070, %f1071;
	selp.f32	%f1073, 0fBF000000, 0fBE2AAAAB, %p114;
	fma.rn.f32 	%f1074, %f1052, %f1072, %f1073;
	fma.rn.f32 	%f1075, %f1052, %f1074, 0f3F800000;
	selp.f32	%f1076, 0f3F800000, %f1051, %p114;
	mul.f32 	%f1077, %f1076, %f1075;
	sub.f32 	%f1078, %f1035, %f1077;
	setp.gt.u32	%p115, %r344, 1;
	selp.f32	%f1079, %f1078, %f1077, %p115;
	mul.f32 	%f1080, %f309, %f1079;
	mul.f32 	%f1081, %f1505, %f1080;
	fma.rn.f32 	%f1082, %f1500, %f1065, %f1081;
	fma.rn.f32 	%f312, %f1038, %f1508, %f1082;
	mul.f32 	%f1083, %f1503, %f1080;
	fma.rn.f32 	%f1084, %f1502, %f1065, %f1083;
	fma.rn.f32 	%f310, %f1038, %f1506, %f1084;
	mul.f32 	%f1085, %f1504, %f1080;
	fma.rn.f32 	%f1086, %f1501, %f1065, %f1085;
	fma.rn.f32 	%f311, %f1038, %f1507, %f1086;
	mul.f32 	%f1087, %f311, %f294;
	fma.rn.f32 	%f1088, %f310, %f293, %f1087;
	fma.rn.f32 	%f313, %f312, %f295, %f1088;
	mul.f32 	%f1089, %f313, %f313;
	sub.f32 	%f314, %f1089, %f296;
	setp.gtu.f32	%p116, %f314, 0f00000000;
	and.pred  	%p118, %p116, %p10;
	selp.u32	%r329, 1, 0, %p118;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r329, 0; 
         vote.ballot.b32  %r328, %p1; 
      }
	// inline asm
	setp.eq.s32	%p119, %r328, 0;
	mov.u32 	%r511, 0;
	mov.f32 	%f1483, 0f5BB1A2BC;
	@%p119 bra 	BB1_53;

	mov.f32 	%f1444, 0f00000000;
	sqrt.rn.f32 	%f1092, %f314;
	sub.f32 	%f1093, %f1444, %f313;
	sub.f32 	%f315, %f1093, %f1092;
	setp.gtu.f32	%p121, %f315, 0f00000000;
	setp.ltu.f32	%p122, %f315, 0f5BB1A2BC;
	and.pred  	%p123, %p121, %p122;
	and.pred  	%p124, %p116, %p123;
	and.pred  	%p14, %p124, %p10;
	selp.u32	%r346, 1, 0, %p14;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r346, 0; 
         vote.ballot.b32  %r345, %p1; 
      }
	// inline asm
	setp.eq.s32	%p125, %r345, 0;
	mov.u32 	%r511, 0;
	@%p125 bra 	BB1_53;

	selp.f32	%f1483, %f315, 0f5BB1A2BC, %p14;
	selp.b32	%r511, 1, 0, %p14;

BB1_53:
	mul.f32 	%f1094, %f311, %f298;
	fma.rn.f32 	%f1095, %f310, %f297, %f1094;
	fma.rn.f32 	%f318, %f312, %f299, %f1095;
	mul.f32 	%f1096, %f318, %f318;
	sub.f32 	%f319, %f1096, %f300;
	setp.gtu.f32	%p126, %f319, 0f00000000;
	and.pred  	%p128, %p126, %p10;
	selp.u32	%r349, 1, 0, %p128;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r349, 0; 
         vote.ballot.b32  %r348, %p1; 
      }
	// inline asm
	setp.eq.s32	%p129, %r348, 0;
	@%p129 bra 	BB1_56;

	mov.f32 	%f1445, 0f00000000;
	sqrt.rn.f32 	%f1098, %f319;
	sub.f32 	%f1099, %f1445, %f318;
	sub.f32 	%f320, %f1099, %f1098;
	setp.gtu.f32	%p131, %f320, 0f00000000;
	setp.ltu.f32	%p132, %f320, %f1483;
	and.pred  	%p133, %p131, %p132;
	and.pred  	%p134, %p126, %p133;
	and.pred  	%p15, %p134, %p10;
	selp.u32	%r351, 1, 0, %p15;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r351, 0; 
         vote.ballot.b32  %r350, %p1; 
      }
	// inline asm
	setp.eq.s32	%p135, %r350, 0;
	@%p135 bra 	BB1_56;

	selp.f32	%f1483, %f320, %f1483, %p15;
	selp.b32	%r511, 1, %r511, %p15;

BB1_56:
	mul.f32 	%f1100, %f311, %f302;
	fma.rn.f32 	%f1101, %f310, %f301, %f1100;
	fma.rn.f32 	%f323, %f312, %f303, %f1101;
	mul.f32 	%f1102, %f323, %f323;
	sub.f32 	%f324, %f1102, %f304;
	setp.gtu.f32	%p136, %f324, 0f00000000;
	and.pred  	%p138, %p136, %p10;
	selp.u32	%r353, 1, 0, %p138;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r353, 0; 
         vote.ballot.b32  %r352, %p1; 
      }
	// inline asm
	setp.eq.s32	%p139, %r352, 0;
	@%p139 bra 	BB1_59;

	mov.f32 	%f1446, 0f00000000;
	sqrt.rn.f32 	%f1104, %f324;
	sub.f32 	%f1105, %f1446, %f323;
	sub.f32 	%f325, %f1105, %f1104;
	setp.gtu.f32	%p141, %f325, 0f00000000;
	setp.ltu.f32	%p142, %f325, %f1483;
	and.pred  	%p143, %p141, %p142;
	and.pred  	%p144, %p136, %p143;
	and.pred  	%p16, %p144, %p10;
	selp.u32	%r355, 1, 0, %p16;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r355, 0; 
         vote.ballot.b32  %r354, %p1; 
      }
	// inline asm
	setp.eq.s32	%p145, %r354, 0;
	@%p145 bra 	BB1_59;

	selp.f32	%f1483, %f325, %f1483, %p16;
	selp.b32	%r511, 1, %r511, %p16;

BB1_59:
	mul.f32 	%f1106, %f311, %f853;
	fma.rn.f32 	%f1107, %f310, %f852, %f1106;
	fma.rn.f32 	%f328, %f312, %f854, %f1107;
	mov.b32 	 %r358, %f328;
	and.b32  	%r359, %r358, 2147483647;
	mov.b32 	 %f329, %r359;
	setp.ltu.f32	%p146, %f329, 0f233877AA;
	and.pred  	%p148, %p146, %p10;
	selp.u32	%r357, 1, 0, %p148;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r357, 0; 
         vote.ballot.b32  %r356, %p1; 
      }
	// inline asm
	setp.eq.s32	%p149, %r356, 0;
	xor.pred  	%p150, %p10, %p148;
	or.pred  	%p151, %p149, %p150;
	@!%p151 bra 	BB1_63;
	bra.uni 	BB1_60;

BB1_60:
	setp.ge.f32	%p17, %f329, 0f233877AA;
	and.pred  	%p153, %p10, %p17;
	selp.u32	%r361, 1, 0, %p153;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r361, 0; 
         vote.ballot.b32  %r360, %p1; 
      }
	// inline asm
	setp.eq.s32	%p154, %r360, 0;
	@%p154 bra 	BB1_63;

	div.rn.f32 	%f1108, %f305, %f328;
	setp.gtu.f32	%p155, %f1108, 0f00000000;
	setp.ltu.f32	%p156, %f1108, %f1483;
	and.pred  	%p157, %p155, %p156;
	and.pred  	%p158, %p157, %p17;
	and.pred  	%p18, %p158, %p10;
	selp.u32	%r363, 1, 0, %p18;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r363, 0; 
         vote.ballot.b32  %r362, %p1; 
      }
	// inline asm
	setp.eq.s32	%p159, %r362, 0;
	@%p159 bra 	BB1_63;

	selp.b32	%r511, 1, %r511, %p18;

BB1_63:
	add.s32 	%r510, %r510, 1;
	setp.ne.s32	%p160, %r511, 0;
	add.f32 	%f1109, %f1482, 0f3F800000;
	selp.f32	%f1482, %f1109, %f1482, %p160;
	setp.ne.s32	%p161, %r510, 8;
	@%p161 bra 	BB1_46;

	add.s32 	%r509, %r509, 1;
	setp.ne.s32	%p162, %r509, 8;
	@%p162 bra 	BB1_45;

	mov.f32 	%f1110, 0f42800000;
	sub.f32 	%f1111, %f1110, %f1482;
	div.rn.f32 	%f1112, %f1111, 0f42800000;
	selp.f32	%f1113, %f1112, 0f00000000, %p10;
	mul.f32 	%f1114, %f4, %f1113;
	selp.f32	%f1115, %f1114, 0f00000000, %p10;
	add.f32 	%f1116, %f1484, %f1115;
	selp.f32	%f1484, %f1116, %f1484, %p10;

BB1_66:
	add.s32 	%r507, %r507, 1;
	setp.ne.s32	%p164, %r507, %r192;
	@%p164 bra 	BB1_10;

	add.s32 	%r506, %r506, 1;
	setp.ne.s32	%p165, %r506, %r192;
	@%p165 bra 	BB1_9;

BB1_68:
	cvt.u32.u16	%r364, %rs1;
	and.b32  	%r365, %r364, 255;
	add.s32 	%r366, %r519, %r365;
	mad.lo.s32 	%r367, %r22, %r190, %r366;
	mul.lo.s32 	%r368, %r367, 12;
	cvt.s64.s32	%rd8, %r368;
	add.s64 	%rd9, %rd8, %rd2;
	st.f32 	[%rd9], %f1484;
	add.s32 	%r369, %r368, 4;
	cvt.s64.s32	%rd10, %r369;
	add.s64 	%rd11, %rd10, %rd2;
	st.f32 	[%rd11], %f1484;
	add.s32 	%r370, %r368, 8;
	cvt.s64.s32	%rd12, %r370;
	add.s64 	%rd13, %rd12, %rd2;
	st.f32 	[%rd13], %f1484;
	add.s32 	%r519, %r519, 8;
	setp.lt.s32	%p166, %r519, %r9;
	mov.u32 	%r518, %r519;
	@%p166 bra 	BB1_7;

BB1_69:
	mov.u32 	%r516, %r518;
	setp.ge.s32	%p167, %r516, %r4;
	@%p167 bra 	BB1_79;

	mov.u64 	%rd15, constDeltaForeach3;
	add.s64 	%rd16, %rd15, %rd3;
	ld.global.u8 	%r373, [%rd16];
	add.s32 	%r520, %r516, %r373;
	setp.lt.s32	%p19, %r520, %r4;
	mov.pred 	%p301, 0;
	mov.pred 	%p302, %p19;
	bra.uni 	BB1_75;

BB1_71:
	add.s32 	%r189, %r516, 8;
	mov.u32 	%r517, %r189;

BB1_72:
	mov.u32 	%r514, %r517;
	mov.u32 	%r516, %r514;
	mov.u64 	%rd18, constDeltaForeach3;
	add.s64 	%rd19, %rd18, %rd3;
	ld.global.u8 	%r376, [%rd19];
	setp.ge.s32	%p169, %r516, %r9;
	add.s32 	%r520, %r516, %r376;
	@%p169 bra 	BB1_74;

	mov.pred 	%p301, -1;
	mov.pred 	%p302, %p1;
	bra.uni 	BB1_75;

BB1_74:
	setp.lt.s32	%p171, %r520, %r4;
	setp.lt.s32	%p172, %r22, %r6;
	and.pred  	%p20, %p172, %p171;
	mov.pred 	%p301, 0;
	mov.pred 	%p302, %p20;

BB1_75:
	mov.pred 	%p22, %p302;
	setp.gt.s32	%p174, %r192, 0;
	mad.lo.s32 	%r114, %r22, %r190, %r520;
	@%p174 bra 	BB1_81;

	mov.f32 	%f1515, 0f00000000;
	@%p22 bra 	BB1_77;
	bra.uni 	BB1_78;

BB1_77:
	mul.lo.s32 	%r496, %r114, 12;
	cvt.s64.s32	%rd20, %r496;
	add.s64 	%rd21, %rd20, %rd2;
	st.f32 	[%rd21], %f1515;
	add.s32 	%r497, %r496, 4;
	cvt.s64.s32	%rd22, %r497;
	add.s64 	%rd23, %rd22, %rd2;
	st.f32 	[%rd23], %f1515;
	add.s32 	%r498, %r496, 8;
	cvt.s64.s32	%rd24, %r498;
	add.s64 	%rd25, %rd24, %rd2;
	st.f32 	[%rd25], %f1515;

BB1_78:
	@%p301 bra 	BB1_71;

BB1_79:
	add.s32 	%r504, %r505, 4;
	setp.lt.s32	%p300, %r504, %r6;
	mov.u32 	%r505, %r504;
	@%p300 bra 	BB1_4;

BB1_80:
	ret;

BB1_81:
	ld.global.v4.f32 	{%f1119, %f1120, %f1121, %f1122}, [static_211_spheres];
	ld.global.f32 	%f1123, [static_211_spheres+128];
	ld.global.v4.f32 	{%f1124, %f1125, %f1126, %f1127}, [static_211_spheres+256];
	ld.global.f32 	%f1128, [static_211_spheres+384];
	ld.global.v4.f32 	{%f1129, %f1130, %f1131, %f1132}, [static_211_spheres+512];
	ld.global.f32 	%f1133, [static_211_spheres+640];
	ld.global.v4.f32 	{%f1134, %f1135, %f1136, %f1137}, [static_210_plane];
	ld.global.v4.f32 	{%f1141, %f1142, %f1143, %f1144}, [static_210_plane+128];
	mul.f32 	%f1145, %f1135, %f1142;
	fma.rn.f32 	%f1146, %f1134, %f1141, %f1145;
	fma.rn.f32 	%f528, %f1136, %f1143, %f1146;
	mul.f32 	%f1147, %f1142, 0f00000000;
	fma.rn.f32 	%f1148, %f1141, 0f00000000, %f1147;
	fma.rn.f32 	%f1149, %f1143, 0f00000000, %f1148;
	sub.f32 	%f1150, %f1149, %f528;
	mov.f32 	%f1515, 0f00000000;
	sub.f32 	%f529, %f1515, %f1150;
	mul.f32 	%f1151, %f1130, %f1130;
	fma.rn.f32 	%f1152, %f1129, %f1129, %f1151;
	fma.rn.f32 	%f1153, %f1131, %f1131, %f1152;
	mul.f32 	%f523, %f1133, %f1133;
	sub.f32 	%f524, %f1153, %f523;
	mul.f32 	%f1154, %f1125, %f1125;
	fma.rn.f32 	%f1155, %f1124, %f1124, %f1154;
	fma.rn.f32 	%f1156, %f1126, %f1126, %f1155;
	mul.f32 	%f486, %f1128, %f1128;
	sub.f32 	%f487, %f1156, %f486;
	mul.f32 	%f1157, %f1120, %f1120;
	fma.rn.f32 	%f1158, %f1119, %f1119, %f1157;
	fma.rn.f32 	%f1159, %f1121, %f1121, %f1158;
	mul.f32 	%f449, %f1123, %f1123;
	sub.f32 	%f450, %f1159, %f449;
	cvt.rn.f32.s32	%f415, %r520;
	mov.u32 	%r521, 0;

BB1_82:
	mov.u32 	%r522, 0;
	cvt.rn.f32.s32	%f1244, %r521;
	fma.rn.f32 	%f1245, %f1, %f1244, %f415;
	sub.f32 	%f1246, %f1245, %f2;
	div.rn.f32 	%f546, %f1246, %f2;

BB1_83:
	cvt.rn.f32.s32	%f1471, %r22;
	mul.f32 	%f1470, %f546, %f546;
	cvt.rn.f32.s32	%f1248, %r522;
	mov.f32 	%f1498, 0f00000000;
	fma.rn.f32 	%f1250, %f1, %f1248, %f1471;
	sub.f32 	%f1251, %f1250, %f3;
	sub.f32 	%f1252, %f1498, %f1251;
	div.rn.f32 	%f1492, %f1252, %f3;
	fma.rn.f32 	%f1253, %f1492, %f1492, %f1470;
	add.f32 	%f1254, %f1253, 0f3F800000;
	rsqrt.approx.f32 	%f565, %f1254;
	mov.f32 	%f1491, 0fBF800000;
	mov.f32 	%f1493, %f546;
	@!%p22 bra 	BB1_85;
	bra.uni 	BB1_84;

BB1_84:
	mul.f32 	%f1492, %f565, %f1492;
	mul.f32 	%f566, %f565, %f546;
	neg.f32 	%f1491, %f565;
	mov.f32 	%f1493, %f566;

BB1_85:
	mov.f32 	%f571, %f1493;
	sub.f32 	%f1257, %f1498, %f1119;
	sub.f32 	%f1258, %f1498, %f1120;
	mul.f32 	%f1259, %f1492, %f1258;
	fma.rn.f32 	%f1260, %f571, %f1257, %f1259;
	sub.f32 	%f1261, %f1498, %f1121;
	fma.rn.f32 	%f572, %f1491, %f1261, %f1260;
	mul.f32 	%f1262, %f572, %f572;
	sub.f32 	%f573, %f1262, %f450;
	setp.gtu.f32	%p175, %f573, 0f00000000;
	and.pred  	%p176, %p175, %p22;
	selp.u32	%r380, 1, 0, %p176;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r380, 0; 
         vote.ballot.b32  %r379, %p1; 
      }
	// inline asm
	setp.eq.s32	%p177, %r379, 0;
	mov.u32 	%r523, 0;
	mov.f32 	%f1494, 0f5BB1A2BC;
	@%p177 bra 	BB1_93;

	sqrt.rn.f32 	%f1265, %f573;
	sub.f32 	%f1266, %f1498, %f572;
	sub.f32 	%f574, %f1266, %f1265;
	setp.gtu.f32	%p179, %f574, 0f00000000;
	setp.ltu.f32	%p180, %f574, 0f5BB1A2BC;
	and.pred  	%p181, %p179, %p180;
	and.pred  	%p182, %p175, %p181;
	and.pred  	%p24, %p182, %p22;
	selp.u32	%r383, 1, 0, %p24;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r383, 0; 
         vote.ballot.b32  %r382, %p1; 
      }
	// inline asm
	setp.eq.s32	%p183, %r382, 0;
	mov.u32 	%r523, 0;
	@%p183 bra 	BB1_93;

	selp.f32	%f1494, %f574, 0f5BB1A2BC, %p24;
	selp.b32	%r523, 1, 0, %p24;
	@!%p24 bra 	BB1_89;
	bra.uni 	BB1_88;

BB1_88:
	fma.rn.f32 	%f1512, %f574, %f1491, 0f00000000;
	fma.rn.f32 	%f1513, %f574, %f1492, 0f00000000;
	fma.rn.f32 	%f1514, %f574, %f571, 0f00000000;

BB1_89:
	@!%p24 bra 	BB1_91;
	bra.uni 	BB1_90;

BB1_90:
	sub.f32 	%f1511, %f1514, %f1119;
	sub.f32 	%f1510, %f1513, %f1120;
	sub.f32 	%f1509, %f1512, %f1121;

BB1_91:
	mul.f32 	%f1267, %f1510, %f1510;
	fma.rn.f32 	%f1268, %f1511, %f1511, %f1267;
	fma.rn.f32 	%f1269, %f1509, %f1509, %f1268;
	rsqrt.approx.f32 	%f588, %f1269;
	@!%p24 bra 	BB1_93;
	bra.uni 	BB1_92;

BB1_92:
	mul.f32 	%f1509, %f588, %f1509;
	mul.f32 	%f1510, %f588, %f1510;
	mul.f32 	%f1511, %f588, %f1511;

BB1_93:
	sub.f32 	%f1271, %f1498, %f1124;
	sub.f32 	%f1272, %f1498, %f1125;
	mul.f32 	%f1273, %f1492, %f1272;
	fma.rn.f32 	%f1274, %f571, %f1271, %f1273;
	sub.f32 	%f1275, %f1498, %f1126;
	fma.rn.f32 	%f599, %f1491, %f1275, %f1274;
	mul.f32 	%f1276, %f599, %f599;
	sub.f32 	%f600, %f1276, %f487;
	setp.gtu.f32	%p184, %f600, 0f00000000;
	and.pred  	%p185, %p184, %p22;
	selp.u32	%r386, 1, 0, %p185;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r386, 0; 
         vote.ballot.b32  %r385, %p1; 
      }
	// inline asm
	setp.eq.s32	%p186, %r385, 0;
	@%p186 bra 	BB1_101;

	sqrt.rn.f32 	%f1278, %f600;
	sub.f32 	%f1279, %f1498, %f599;
	sub.f32 	%f601, %f1279, %f1278;
	setp.gtu.f32	%p188, %f601, 0f00000000;
	setp.ltu.f32	%p189, %f601, %f1494;
	and.pred  	%p190, %p188, %p189;
	and.pred  	%p191, %p184, %p190;
	and.pred  	%p25, %p191, %p22;
	selp.u32	%r388, 1, 0, %p25;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r388, 0; 
         vote.ballot.b32  %r387, %p1; 
      }
	// inline asm
	setp.eq.s32	%p192, %r387, 0;
	@%p192 bra 	BB1_101;

	selp.f32	%f1494, %f601, %f1494, %p25;
	selp.b32	%r523, 1, %r523, %p25;
	@!%p25 bra 	BB1_97;
	bra.uni 	BB1_96;

BB1_96:
	fma.rn.f32 	%f1512, %f601, %f1491, 0f00000000;
	fma.rn.f32 	%f1513, %f601, %f1492, 0f00000000;
	fma.rn.f32 	%f1514, %f601, %f571, 0f00000000;

BB1_97:
	@!%p25 bra 	BB1_99;
	bra.uni 	BB1_98;

BB1_98:
	sub.f32 	%f1509, %f1512, %f1126;
	sub.f32 	%f1510, %f1513, %f1125;
	sub.f32 	%f1511, %f1514, %f1124;

BB1_99:
	mul.f32 	%f1280, %f1510, %f1510;
	fma.rn.f32 	%f1281, %f1511, %f1511, %f1280;
	fma.rn.f32 	%f1282, %f1509, %f1509, %f1281;
	rsqrt.approx.f32 	%f615, %f1282;
	@!%p25 bra 	BB1_101;
	bra.uni 	BB1_100;

BB1_100:
	mul.f32 	%f1509, %f615, %f1509;
	mul.f32 	%f1510, %f615, %f1510;
	mul.f32 	%f1511, %f615, %f1511;

BB1_101:
	sub.f32 	%f1284, %f1498, %f1129;
	sub.f32 	%f1285, %f1498, %f1130;
	mul.f32 	%f1286, %f1492, %f1285;
	fma.rn.f32 	%f1287, %f571, %f1284, %f1286;
	sub.f32 	%f1288, %f1498, %f1131;
	fma.rn.f32 	%f626, %f1491, %f1288, %f1287;
	mul.f32 	%f1289, %f626, %f626;
	sub.f32 	%f627, %f1289, %f524;
	setp.gtu.f32	%p193, %f627, 0f00000000;
	and.pred  	%p194, %p193, %p22;
	selp.u32	%r390, 1, 0, %p194;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r390, 0; 
         vote.ballot.b32  %r389, %p1; 
      }
	// inline asm
	setp.eq.s32	%p195, %r389, 0;
	@%p195 bra 	BB1_109;

	sqrt.rn.f32 	%f1291, %f627;
	sub.f32 	%f1292, %f1498, %f626;
	sub.f32 	%f628, %f1292, %f1291;
	setp.gtu.f32	%p197, %f628, 0f00000000;
	setp.ltu.f32	%p198, %f628, %f1494;
	and.pred  	%p199, %p197, %p198;
	and.pred  	%p200, %p193, %p199;
	and.pred  	%p26, %p200, %p22;
	selp.u32	%r392, 1, 0, %p26;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r392, 0; 
         vote.ballot.b32  %r391, %p1; 
      }
	// inline asm
	setp.eq.s32	%p201, %r391, 0;
	@%p201 bra 	BB1_109;

	selp.f32	%f1494, %f628, %f1494, %p26;
	selp.b32	%r523, 1, %r523, %p26;
	@!%p26 bra 	BB1_105;
	bra.uni 	BB1_104;

BB1_104:
	fma.rn.f32 	%f1512, %f628, %f1491, 0f00000000;
	fma.rn.f32 	%f1513, %f628, %f1492, 0f00000000;
	fma.rn.f32 	%f1514, %f628, %f571, 0f00000000;

BB1_105:
	@!%p26 bra 	BB1_107;
	bra.uni 	BB1_106;

BB1_106:
	sub.f32 	%f1509, %f1512, %f1131;
	sub.f32 	%f1510, %f1513, %f1130;
	sub.f32 	%f1511, %f1514, %f1129;

BB1_107:
	mul.f32 	%f1293, %f1510, %f1510;
	fma.rn.f32 	%f1294, %f1511, %f1511, %f1293;
	fma.rn.f32 	%f1295, %f1509, %f1509, %f1294;
	rsqrt.approx.f32 	%f642, %f1295;
	@!%p26 bra 	BB1_109;
	bra.uni 	BB1_108;

BB1_108:
	mul.f32 	%f1509, %f642, %f1509;
	mul.f32 	%f1510, %f642, %f1510;
	mul.f32 	%f1511, %f642, %f1511;

BB1_109:
	mul.f32 	%f1296, %f1492, %f1142;
	fma.rn.f32 	%f1297, %f571, %f1141, %f1296;
	fma.rn.f32 	%f653, %f1491, %f1143, %f1297;
	mov.b32 	 %r395, %f653;
	and.b32  	%r396, %r395, 2147483647;
	mov.b32 	 %f654, %r396;
	setp.ltu.f32	%p202, %f654, 0f233877AA;
	and.pred  	%p203, %p202, %p22;
	selp.u32	%r394, 1, 0, %p203;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r394, 0; 
         vote.ballot.b32  %r393, %p1; 
      }
	// inline asm
	setp.eq.s32	%p204, %r393, 0;
	xor.pred  	%p205, %p22, %p203;
	or.pred  	%p206, %p204, %p205;
	@!%p206 bra 	BB1_114;
	bra.uni 	BB1_110;

BB1_110:
	setp.ge.f32	%p27, %f654, 0f233877AA;
	and.pred  	%p207, %p22, %p27;
	selp.u32	%r398, 1, 0, %p207;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r398, 0; 
         vote.ballot.b32  %r397, %p1; 
      }
	// inline asm
	setp.eq.s32	%p208, %r397, 0;
	@%p208 bra 	BB1_114;

	div.rn.f32 	%f655, %f529, %f653;
	setp.gtu.f32	%p209, %f655, 0f00000000;
	setp.ltu.f32	%p210, %f655, %f1494;
	and.pred  	%p211, %p209, %p210;
	and.pred  	%p212, %p211, %p27;
	and.pred  	%p28, %p212, %p22;
	selp.u32	%r400, 1, 0, %p28;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r400, 0; 
         vote.ballot.b32  %r399, %p1; 
      }
	// inline asm
	setp.eq.s32	%p213, %r399, 0;
	@%p213 bra 	BB1_114;

	selp.b32	%r523, 1, %r523, %p28;
	@!%p28 bra 	BB1_114;
	bra.uni 	BB1_113;

BB1_113:
	mov.f32 	%f1511, %f1141;
	mov.f32 	%f1510, %f1142;
	mov.f32 	%f1509, %f1143;
	fma.rn.f32 	%f1512, %f655, %f1491, 0f00000000;
	fma.rn.f32 	%f1513, %f655, %f1492, 0f00000000;
	fma.rn.f32 	%f1514, %f655, %f571, 0f00000000;

BB1_114:
	setp.ne.s32	%p214, %r523, 0;
	and.pred  	%p30, %p22, %p214;
	selp.u32	%r402, 1, 0, %p30;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r402, 0; 
         vote.ballot.b32  %r401, %p1; 
      }
	// inline asm
	setp.eq.s32	%p215, %r401, 0;
	@%p215 bra 	BB1_141;

	setp.gtu.f32	%p216, %f1511, 0fBF19999A;
	setp.ltu.f32	%p217, %f1511, 0f3F19999A;
	and.pred  	%p218, %p217, %p216;
	and.pred  	%p219, %p218, %p30;
	selp.u32	%r404, 1, 0, %p219;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r404, 0; 
         vote.ballot.b32  %r403, %p1; 
      }
	// inline asm
	setp.eq.s32	%p220, %r403, 0;
	setp.le.f32	%p221, %f1511, 0fBF19999A;
	setp.ge.f32	%p222, %f1511, 0f3F19999A;
	or.pred  	%p31, %p222, %p221;
	and.pred  	%p223, %p30, %p31;
	selp.u32	%r406, 1, 0, %p223;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r406, 0; 
         vote.ballot.b32  %r405, %p1; 
      }
	// inline asm
	setp.eq.s32	%p224, %r405, 0;
	selp.f32	%f1508, %f1509, %f1508, %p30;
	selp.f32	%f1507, %f1510, %f1507, %p30;
	selp.f32	%f1506, %f1511, %f1506, %p30;
	selp.f32	%f1298, 0f00000000, %f1503, %p30;
	selp.f32	%f1299, 0f3F800000, %f1298, %p219;
	selp.f32	%f1495, %f1298, %f1299, %p220;
	selp.f32	%f1497, 0f00000000, %f1505, %p30;
	selp.f32	%f1496, 0f00000000, %f1504, %p30;
	fma.rn.f32 	%f667, %f1509, 0f38D1B717, %f1512;
	fma.rn.f32 	%f666, %f1510, 0f38D1B717, %f1513;
	fma.rn.f32 	%f665, %f1511, 0f38D1B717, %f1514;
	@%p224 bra 	BB1_119;

	setp.gtu.f32	%p225, %f1510, 0fBF19999A;
	setp.ltu.f32	%p226, %f1510, 0f3F19999A;
	and.pred  	%p227, %p226, %p225;
	and.pred  	%p228, %p227, %p31;
	and.pred  	%p229, %p228, %p30;
	selp.u32	%r408, 1, 0, %p229;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r408, 0; 
         vote.ballot.b32  %r407, %p1; 
      }
	// inline asm
	setp.eq.s32	%p230, %r407, 0;
	setp.le.f32	%p231, %f1510, 0fBF19999A;
	setp.ge.f32	%p232, %f1510, 0f3F19999A;
	or.pred  	%p233, %p232, %p231;
	and.pred  	%p32, %p31, %p233;
	and.pred  	%p234, %p32, %p30;
	selp.u32	%r410, 1, 0, %p234;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r410, 0; 
         vote.ballot.b32  %r409, %p1; 
      }
	// inline asm
	setp.eq.s32	%p235, %r409, 0;
	selp.f32	%f1300, 0f3F800000, %f1496, %p229;
	selp.f32	%f1496, %f1496, %f1300, %p230;
	@%p235 bra 	BB1_119;

	setp.gtu.f32	%p236, %f1509, 0fBF19999A;
	setp.ltu.f32	%p237, %f1509, 0f3F19999A;
	and.pred  	%p238, %p237, %p236;
	and.pred  	%p239, %p32, %p238;
	and.pred  	%p240, %p239, %p30;
	selp.u32	%r412, 1, 0, %p240;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r412, 0; 
         vote.ballot.b32  %r411, %p1; 
      }
	// inline asm
	setp.eq.s32	%p241, %r411, 0;
	setp.le.f32	%p242, %f1509, 0fBF19999A;
	setp.ge.f32	%p243, %f1509, 0f3F19999A;
	or.pred  	%p244, %p243, %p242;
	and.pred  	%p245, %p32, %p244;
	and.pred  	%p33, %p245, %p30;
	selp.u32	%r414, 1, 0, %p33;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r414, 0; 
         vote.ballot.b32  %r413, %p1; 
      }
	// inline asm
	setp.eq.s32	%p246, %r413, 0;
	selp.f32	%f1301, 0f3F800000, %f1497, %p240;
	selp.f32	%f1497, %f1497, %f1301, %p241;
	@%p246 bra 	BB1_119;

	selp.f32	%f1495, 0f3F800000, %f1495, %p33;

BB1_119:
	mul.f32 	%f1474, %f1123, %f1123;
	mul.f32 	%f1473, %f1128, %f1128;
	mul.f32 	%f1472, %f1133, %f1133;
	mul.f32 	%f1303, %f1497, %f1507;
	mul.f32 	%f1304, %f1496, %f1508;
	sub.f32 	%f1305, %f1304, %f1303;
	selp.f32	%f1306, %f1305, %f1502, %p30;
	mul.f32 	%f1307, %f1495, %f1508;
	mul.f32 	%f1308, %f1497, %f1506;
	sub.f32 	%f1309, %f1308, %f1307;
	selp.f32	%f1310, %f1309, %f1501, %p30;
	mul.f32 	%f1311, %f1310, %f1310;
	fma.rn.f32 	%f1312, %f1306, %f1306, %f1311;
	mul.f32 	%f1313, %f1496, %f1506;
	mul.f32 	%f1314, %f1495, %f1507;
	sub.f32 	%f1315, %f1314, %f1313;
	selp.f32	%f1316, %f1315, %f1500, %p30;
	fma.rn.f32 	%f1317, %f1316, %f1316, %f1312;
	rsqrt.approx.f32 	%f1318, %f1317;
	mul.f32 	%f1319, %f1318, %f1310;
	selp.f32	%f1501, %f1319, %f1501, %p30;
	mul.f32 	%f1320, %f1508, %f1501;
	mul.f32 	%f1321, %f1318, %f1316;
	selp.f32	%f1500, %f1321, %f1500, %p30;
	mul.f32 	%f1322, %f1507, %f1500;
	sub.f32 	%f1323, %f1322, %f1320;
	selp.f32	%f1324, %f1323, %f1495, %p30;
	mul.f32 	%f1325, %f1506, %f1500;
	mul.f32 	%f1326, %f1318, %f1306;
	selp.f32	%f1502, %f1326, %f1502, %p30;
	mul.f32 	%f1327, %f1508, %f1502;
	sub.f32 	%f1328, %f1327, %f1325;
	selp.f32	%f1329, %f1328, %f1496, %p30;
	mul.f32 	%f1330, %f1329, %f1329;
	fma.rn.f32 	%f1331, %f1324, %f1324, %f1330;
	mul.f32 	%f1332, %f1507, %f1502;
	mul.f32 	%f1333, %f1506, %f1501;
	sub.f32 	%f1334, %f1333, %f1332;
	selp.f32	%f1335, %f1334, %f1497, %p30;
	fma.rn.f32 	%f1336, %f1335, %f1335, %f1331;
	rsqrt.approx.f32 	%f1337, %f1336;
	mul.f32 	%f1338, %f1337, %f1335;
	selp.f32	%f1505, %f1338, %f1497, %p30;
	mul.f32 	%f1339, %f1337, %f1329;
	selp.f32	%f1504, %f1339, %f1496, %p30;
	mul.f32 	%f1340, %f1337, %f1324;
	selp.f32	%f1503, %f1340, %f1495, %p30;
	sub.f32 	%f694, %f665, %f1129;
	sub.f32 	%f695, %f666, %f1130;
	mul.f32 	%f1341, %f695, %f695;
	fma.rn.f32 	%f1342, %f694, %f694, %f1341;
	sub.f32 	%f696, %f667, %f1131;
	fma.rn.f32 	%f1343, %f696, %f696, %f1342;
	sub.f32 	%f697, %f1343, %f1472;
	sub.f32 	%f690, %f665, %f1124;
	sub.f32 	%f691, %f666, %f1125;
	mul.f32 	%f1344, %f691, %f691;
	fma.rn.f32 	%f1345, %f690, %f690, %f1344;
	sub.f32 	%f692, %f667, %f1126;
	fma.rn.f32 	%f1346, %f692, %f692, %f1345;
	sub.f32 	%f693, %f1346, %f1473;
	sub.f32 	%f686, %f665, %f1119;
	sub.f32 	%f687, %f666, %f1120;
	mul.f32 	%f1347, %f687, %f687;
	fma.rn.f32 	%f1348, %f686, %f686, %f1347;
	sub.f32 	%f688, %f667, %f1121;
	fma.rn.f32 	%f1349, %f688, %f688, %f1348;
	sub.f32 	%f689, %f1349, %f1474;
	mul.f32 	%f1350, %f666, %f1142;
	fma.rn.f32 	%f1351, %f665, %f1141, %f1350;
	fma.rn.f32 	%f1352, %f667, %f1143, %f1351;
	sub.f32 	%f1353, %f1352, %f528;
	sub.f32 	%f698, %f1498, %f1353;
	mov.u32 	%r524, 0;

BB1_120:
	mov.u32 	%r525, 0;

BB1_121:
	@!%p30 bra 	BB1_123;
	bra.uni 	BB1_122;

BB1_122:
	shl.b32 	%r417, %r530, 18;
	and.b32  	%r418, %r417, -524288;
	shl.b32 	%r419, %r530, 6;
	xor.b32  	%r420, %r419, %r530;
	shr.u32 	%r421, %r420, 13;
	shl.b32 	%r422, %r529, 2;
	and.b32  	%r423, %r422, -32;
	xor.b32  	%r424, %r422, %r529;
	shr.u32 	%r425, %r424, 27;
	shl.b32 	%r426, %r528, 7;
	and.b32  	%r427, %r426, -2048;
	shl.b32 	%r428, %r528, 13;
	xor.b32  	%r429, %r428, %r528;
	shr.u32 	%r430, %r429, 21;
	shl.b32 	%r431, %r527, 13;
	and.b32  	%r432, %r431, -1048576;
	shl.b32 	%r433, %r527, 3;
	xor.b32  	%r434, %r433, %r527;
	shr.u32 	%r435, %r434, 12;
	or.b32  	%r527, %r435, %r432;
	or.b32  	%r528, %r430, %r427;
	or.b32  	%r529, %r425, %r423;
	or.b32  	%r530, %r421, %r418;

BB1_123:
	xor.b32  	%r436, %r530, %r529;
	xor.b32  	%r437, %r436, %r528;
	xor.b32  	%r438, %r437, %r527;
	and.b32  	%r439, %r438, 8388607;
	or.b32  	%r440, %r439, 1065353216;
	mov.b32 	 %f1354, %r440;
	add.f32 	%f1355, %f1354, 0fBF800000;
	sqrt.rn.f32 	%f702, %f1355;
	@!%p30 bra 	BB1_125;
	bra.uni 	BB1_124;

BB1_124:
	shl.b32 	%r441, %r530, 18;
	and.b32  	%r442, %r441, -524288;
	shl.b32 	%r443, %r530, 6;
	xor.b32  	%r444, %r443, %r530;
	shr.u32 	%r445, %r444, 13;
	shl.b32 	%r446, %r529, 2;
	and.b32  	%r447, %r446, -32;
	xor.b32  	%r448, %r446, %r529;
	shr.u32 	%r449, %r448, 27;
	shl.b32 	%r450, %r528, 7;
	and.b32  	%r451, %r450, -2048;
	shl.b32 	%r452, %r528, 13;
	xor.b32  	%r453, %r452, %r528;
	shr.u32 	%r454, %r453, 21;
	shl.b32 	%r455, %r527, 13;
	and.b32  	%r456, %r455, -1048576;
	shl.b32 	%r457, %r527, 3;
	xor.b32  	%r458, %r457, %r527;
	shr.u32 	%r459, %r458, 12;
	or.b32  	%r527, %r459, %r456;
	or.b32  	%r528, %r454, %r451;
	or.b32  	%r529, %r449, %r447;
	or.b32  	%r530, %r445, %r442;

BB1_125:
	mov.f32 	%f1357, 0f3F800000;
	mov.f32 	%f1358, 0f00000000;
	mul.f32 	%f1359, %f702, %f702;
	sub.f32 	%f1360, %f1357, %f1359;
	sqrt.rn.f32 	%f1361, %f1360;
	xor.b32  	%r463, %r530, %r529;
	xor.b32  	%r464, %r463, %r528;
	xor.b32  	%r465, %r464, %r527;
	and.b32  	%r466, %r465, 8388607;
	or.b32  	%r467, %r466, 1065353216;
	mov.b32 	 %f1362, %r467;
	add.f32 	%f1363, %f1362, 0fBF800000;
	mul.f32 	%f1364, %f1363, 0f40C90FDB;
	mul.f32 	%f1365, %f1364, 0f3F22F983;
	mov.b32 	 %r468, %f1365;
	and.b32  	%r469, %r468, -2147483648;
	xor.b32  	%r470, %r468, %r469;
	mov.b32 	 %f1366, %r470;
	add.f32 	%f1367, %f1366, 0f4B000000;
	add.f32 	%f1368, %f1367, 0fCB000000;
	mov.b32 	 %r471, %f1368;
	xor.b32  	%r472, %r471, %r469;
	mov.b32 	 %f1369, %r472;
	selp.u32	%r473, 1, 0, %p247;
	and.b32  	%r474, %r473, -1082130432;
	mov.b32 	 %f1370, %r474;
	add.f32 	%f1371, %f1369, %f1370;
	cvt.rzi.s32.f32	%r475, %f1371;
	and.b32  	%r476, %r475, 3;
	setp.eq.s32	%p248, %r476, 2;
	setp.eq.s32	%p249, %r476, 0;
	or.pred  	%p250, %p249, %p248;
	selp.f32	%f1372, 0f37CFAB9C, 0f363938A8, %p250;
	selp.f32	%f1373, 0fB48B634D, 0fB2D70013, %p250;
	fma.rn.f32 	%f1374, %f1371, 0fBFC90FDB, %f1364;
	mul.f32 	%f1375, %f1374, %f1374;
	fma.rn.f32 	%f1376, %f1375, %f1373, %f1372;
	selp.f32	%f1377, 0fBAB60981, 0fB9501096, %p250;
	fma.rn.f32 	%f1378, %f1375, %f1376, %f1377;
	selp.f32	%f1379, 0f3D2AAAA4, 0f3C088898, %p250;
	fma.rn.f32 	%f1380, %f1375, %f1378, %f1379;
	selp.f32	%f1381, 0fBF000000, 0fBE2AAAAB, %p250;
	fma.rn.f32 	%f1382, %f1375, %f1380, %f1381;
	fma.rn.f32 	%f1383, %f1375, %f1382, 0f3F800000;
	selp.f32	%f1384, 0f3F800000, %f1374, %p250;
	mul.f32 	%f1385, %f1384, %f1383;
	sub.f32 	%f1386, %f1358, %f1385;
	setp.eq.s32	%p251, %r476, 1;
	or.pred  	%p252, %p251, %p248;
	selp.f32	%f1387, %f1386, %f1385, %p252;
	mul.f32 	%f1388, %f702, %f1387;
	setp.eq.s32	%p253, %r476, 3;
	or.pred  	%p254, %p251, %p253;
	selp.f32	%f1389, 0f37CFAB9C, 0f363938A8, %p254;
	selp.f32	%f1390, 0fB48B634D, 0fB2D70013, %p254;
	fma.rn.f32 	%f1391, %f1375, %f1390, %f1389;
	selp.f32	%f1392, 0fBAB60981, 0fB9501096, %p254;
	fma.rn.f32 	%f1393, %f1375, %f1391, %f1392;
	selp.f32	%f1394, 0f3D2AAAA4, 0f3C088898, %p254;
	fma.rn.f32 	%f1395, %f1375, %f1393, %f1394;
	selp.f32	%f1396, 0fBF000000, 0fBE2AAAAB, %p254;
	fma.rn.f32 	%f1397, %f1375, %f1395, %f1396;
	fma.rn.f32 	%f1398, %f1375, %f1397, 0f3F800000;
	selp.f32	%f1399, 0f3F800000, %f1374, %p254;
	mul.f32 	%f1400, %f1399, %f1398;
	sub.f32 	%f1401, %f1358, %f1400;
	setp.gt.u32	%p255, %r476, 1;
	selp.f32	%f1402, %f1401, %f1400, %p255;
	mul.f32 	%f1403, %f702, %f1402;
	mul.f32 	%f1404, %f1505, %f1403;
	fma.rn.f32 	%f1405, %f1500, %f1388, %f1404;
	fma.rn.f32 	%f705, %f1361, %f1508, %f1405;
	mul.f32 	%f1406, %f1503, %f1403;
	fma.rn.f32 	%f1407, %f1502, %f1388, %f1406;
	fma.rn.f32 	%f703, %f1361, %f1506, %f1407;
	mul.f32 	%f1408, %f1504, %f1403;
	fma.rn.f32 	%f1409, %f1501, %f1388, %f1408;
	fma.rn.f32 	%f704, %f1361, %f1507, %f1409;
	mul.f32 	%f1410, %f704, %f687;
	fma.rn.f32 	%f1411, %f703, %f686, %f1410;
	fma.rn.f32 	%f706, %f705, %f688, %f1411;
	mul.f32 	%f1412, %f706, %f706;
	sub.f32 	%f707, %f1412, %f689;
	setp.gtu.f32	%p256, %f707, 0f00000000;
	and.pred  	%p257, %p256, %p30;
	selp.u32	%r461, 1, 0, %p257;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r461, 0; 
         vote.ballot.b32  %r460, %p1; 
      }
	// inline asm
	setp.eq.s32	%p258, %r460, 0;
	mov.u32 	%r526, 0;
	mov.f32 	%f1499, 0f5BB1A2BC;
	@%p258 bra 	BB1_128;

	mov.f32 	%f1467, 0f00000000;
	sqrt.rn.f32 	%f1415, %f707;
	sub.f32 	%f1416, %f1467, %f706;
	sub.f32 	%f708, %f1416, %f1415;
	setp.gtu.f32	%p260, %f708, 0f00000000;
	setp.ltu.f32	%p261, %f708, 0f5BB1A2BC;
	and.pred  	%p262, %p260, %p261;
	and.pred  	%p263, %p256, %p262;
	and.pred  	%p34, %p263, %p30;
	selp.u32	%r478, 1, 0, %p34;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r478, 0; 
         vote.ballot.b32  %r477, %p1; 
      }
	// inline asm
	setp.eq.s32	%p264, %r477, 0;
	mov.u32 	%r526, 0;
	@%p264 bra 	BB1_128;

	selp.f32	%f1499, %f708, 0f5BB1A2BC, %p34;
	selp.b32	%r526, 1, 0, %p34;

BB1_128:
	mul.f32 	%f1417, %f704, %f691;
	fma.rn.f32 	%f1418, %f703, %f690, %f1417;
	fma.rn.f32 	%f711, %f705, %f692, %f1418;
	mul.f32 	%f1419, %f711, %f711;
	sub.f32 	%f712, %f1419, %f693;
	setp.gtu.f32	%p265, %f712, 0f00000000;
	and.pred  	%p266, %p265, %p30;
	selp.u32	%r481, 1, 0, %p266;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r481, 0; 
         vote.ballot.b32  %r480, %p1; 
      }
	// inline asm
	setp.eq.s32	%p267, %r480, 0;
	@%p267 bra 	BB1_131;

	mov.f32 	%f1468, 0f00000000;
	sqrt.rn.f32 	%f1421, %f712;
	sub.f32 	%f1422, %f1468, %f711;
	sub.f32 	%f713, %f1422, %f1421;
	setp.gtu.f32	%p269, %f713, 0f00000000;
	setp.ltu.f32	%p270, %f713, %f1499;
	and.pred  	%p271, %p269, %p270;
	and.pred  	%p272, %p265, %p271;
	and.pred  	%p35, %p272, %p30;
	selp.u32	%r483, 1, 0, %p35;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r483, 0; 
         vote.ballot.b32  %r482, %p1; 
      }
	// inline asm
	setp.eq.s32	%p273, %r482, 0;
	@%p273 bra 	BB1_131;

	selp.f32	%f1499, %f713, %f1499, %p35;
	selp.b32	%r526, 1, %r526, %p35;

BB1_131:
	mul.f32 	%f1423, %f704, %f695;
	fma.rn.f32 	%f1424, %f703, %f694, %f1423;
	fma.rn.f32 	%f716, %f705, %f696, %f1424;
	mul.f32 	%f1425, %f716, %f716;
	sub.f32 	%f717, %f1425, %f697;
	setp.gtu.f32	%p274, %f717, 0f00000000;
	and.pred  	%p275, %p274, %p30;
	selp.u32	%r485, 1, 0, %p275;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r485, 0; 
         vote.ballot.b32  %r484, %p1; 
      }
	// inline asm
	setp.eq.s32	%p276, %r484, 0;
	@%p276 bra 	BB1_134;

	mov.f32 	%f1469, 0f00000000;
	sqrt.rn.f32 	%f1427, %f717;
	sub.f32 	%f1428, %f1469, %f716;
	sub.f32 	%f718, %f1428, %f1427;
	setp.gtu.f32	%p278, %f718, 0f00000000;
	setp.ltu.f32	%p279, %f718, %f1499;
	and.pred  	%p280, %p278, %p279;
	and.pred  	%p281, %p274, %p280;
	and.pred  	%p36, %p281, %p30;
	selp.u32	%r487, 1, 0, %p36;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r487, 0; 
         vote.ballot.b32  %r486, %p1; 
      }
	// inline asm
	setp.eq.s32	%p282, %r486, 0;
	@%p282 bra 	BB1_134;

	selp.f32	%f1499, %f718, %f1499, %p36;
	selp.b32	%r526, 1, %r526, %p36;

BB1_134:
	mul.f32 	%f1429, %f704, %f1142;
	fma.rn.f32 	%f1430, %f703, %f1141, %f1429;
	fma.rn.f32 	%f721, %f705, %f1143, %f1430;
	mov.b32 	 %r490, %f721;
	and.b32  	%r491, %r490, 2147483647;
	mov.b32 	 %f722, %r491;
	setp.ltu.f32	%p283, %f722, 0f233877AA;
	and.pred  	%p284, %p283, %p30;
	selp.u32	%r489, 1, 0, %p284;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r489, 0; 
         vote.ballot.b32  %r488, %p1; 
      }
	// inline asm
	setp.eq.s32	%p285, %r488, 0;
	xor.pred  	%p286, %p30, %p284;
	or.pred  	%p287, %p285, %p286;
	@!%p287 bra 	BB1_138;
	bra.uni 	BB1_135;

BB1_135:
	setp.ge.f32	%p37, %f722, 0f233877AA;
	and.pred  	%p288, %p30, %p37;
	selp.u32	%r493, 1, 0, %p288;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r493, 0; 
         vote.ballot.b32  %r492, %p1; 
      }
	// inline asm
	setp.eq.s32	%p289, %r492, 0;
	@%p289 bra 	BB1_138;

	div.rn.f32 	%f1431, %f698, %f721;
	setp.gtu.f32	%p290, %f1431, 0f00000000;
	setp.ltu.f32	%p291, %f1431, %f1499;
	and.pred  	%p292, %p290, %p291;
	and.pred  	%p293, %p292, %p37;
	and.pred  	%p38, %p293, %p30;
	selp.u32	%r495, 1, 0, %p38;
	// inline asm
	{ .reg .pred %p1; 
         setp.ne.u32 %p1, %r495, 0; 
         vote.ballot.b32  %r494, %p1; 
      }
	// inline asm
	setp.eq.s32	%p294, %r494, 0;
	@%p294 bra 	BB1_138;

	selp.b32	%r526, 1, %r526, %p38;

BB1_138:
	add.s32 	%r525, %r525, 1;
	setp.ne.s32	%p295, %r526, 0;
	add.f32 	%f1432, %f1498, 0f3F800000;
	selp.f32	%f1498, %f1432, %f1498, %p295;
	setp.ne.s32	%p296, %r525, 8;
	@%p296 bra 	BB1_121;

	add.s32 	%r524, %r524, 1;
	setp.ne.s32	%p297, %r524, 8;
	@%p297 bra 	BB1_120;

	mov.f32 	%f1433, 0f42800000;
	sub.f32 	%f1434, %f1433, %f1498;
	div.rn.f32 	%f1435, %f1434, 0f42800000;
	selp.f32	%f1436, %f1435, 0f00000000, %p30;
	mul.f32 	%f1437, %f4, %f1436;
	selp.f32	%f1438, %f1437, 0f00000000, %p30;
	add.f32 	%f1439, %f1515, %f1438;
	selp.f32	%f1515, %f1439, %f1515, %p30;

BB1_141:
	add.s32 	%r522, %r522, 1;
	setp.ne.s32	%p298, %r522, %r192;
	@%p298 bra 	BB1_83;

	add.s32 	%r521, %r521, 1;
	setp.ne.s32	%p299, %r521, %r192;
	@%p299 bra 	BB1_82;

	@!%p22 bra 	BB1_78;
	bra.uni 	BB1_77;
}

.visible .entry ao_ispc_tasks___uniuniuniun_3C_unf_3E_(
	.param .u32 ao_ispc_tasks___uniuniuniun_3C_unf_3E__param_0,
	.param .u32 ao_ispc_tasks___uniuniuniun_3C_unf_3E__param_1,
	.param .u32 ao_ispc_tasks___uniuniuniun_3C_unf_3E__param_2,
	.param .u64 ao_ispc_tasks___uniuniuniun_3C_unf_3E__param_3,
	.param .align 1 .b8 ao_ispc_tasks___uniuniuniun_3C_unf_3E__param_4[1]
)
{
	.reg .pred 	%p<4>;
	.reg .s32 	%r<28>;
	.reg .s64 	%rd<13>;


	ld.param.u32 	%r4, [ao_ispc_tasks___uniuniuniun_3C_unf_3E__param_0];
	ld.param.u32 	%r5, [ao_ispc_tasks___uniuniuniun_3C_unf_3E__param_1];
	ld.param.u32 	%r6, [ao_ispc_tasks___uniuniuniun_3C_unf_3E__param_2];
	ld.param.u64 	%rd5, [ao_ispc_tasks___uniuniuniun_3C_unf_3E__param_3];
	add.s32 	%r7, %r4, 63;
	shr.s32 	%r8, %r7, 31;
	shr.u32 	%r9, %r8, 26;
	add.s32 	%r10, %r7, %r9;
	shr.s32 	%r1, %r10, 6;
	add.s32 	%r11, %r5, 3;
	shr.s32 	%r12, %r11, 31;
	shr.u32 	%r13, %r12, 30;
	add.s32 	%r14, %r11, %r13;
	shr.s32 	%r2, %r14, 2;
	mov.u32 	%r15, %tid.x;
	and.b32  	%r3, %r15, 31;
	setp.ne.s32	%p1, %r3, 0;
	mov.u64 	%rd12, 0;
	@%p1 bra 	BB2_3;

	mov.u64 	%rd7, 8;
	mov.u64 	%rd8, 24;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd8;
	.param .b64 retval0;
	call.uni (retval0), 
	cudaGetParameterBuffer, 
	(
	param0, 
	param1
	);
	ld.param.b64	%rd1, [retval0+0];
	}
	// Callseq End 0
	setp.eq.s64	%p2, %rd1, 0;
	mov.u64 	%rd12, %rd1;
	@%p2 bra 	BB2_3;

	st.u32 	[%rd1], %r4;
	st.u32 	[%rd1+4], %r5;
	st.u32 	[%rd1+8], %r6;
	st.u64 	[%rd1+16], %rd5;
	mov.u64 	%rd12, %rd1;

BB2_3:
	@%p1 bra 	BB2_5;

	add.s32 	%r24, %r1, -1;
	shr.s32 	%r25, %r24, 2;
	add.s32 	%r17, %r25, 1;
	mov.u32 	%r22, 1;
	mov.u32 	%r20, 128;
	mov.u32 	%r23, 0;
	mov.u64 	%rd11, 0;
	mov.u64 	%rd9, ao_task___UM_uniuniuniun_3C_unf_3E_;
	// inline asm
	{
     .param .b64 param0;
     st.param.b64	[param0+0], %rd9;
     .param .b64 param1;
     st.param.b64	[param1+0], %rd12;
     .param .align 4 .b8 param2[12];
     st.param.b32	[param2+0], %r17; 
     st.param.b32	[param2+4], %r2; 
     st.param.b32	[param2+8], %r22; 
     .param .align 4 .b8 param3[12];
     st.param.b32	[param3+0], %r20; 
     st.param.b32	[param3+4], %r22; 
     st.param.b32	[param3+8], %r22; 
     .param .b32 param4;
     st.param.b32	[param4+0], %r23; 
     .param .b64 param5;
     st.param.b64	[param5+0], %rd11; 

     .param .b32 retval0;
     call.uni (retval0), 
       cudaLaunchDevice,
       (
        param0, 
        param1, 
        param2, 
        param3, 
        param4, 
        param5
       );
     ld.param.b32	%r16, [retval0+0];
  }
  
	// inline asm

BB2_5:
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	cudaDeviceSynchronize, 
	(
	);
	ld.param.b32	%r26, [retval0+0];
	}
	// Callseq End 1
	// Callseq Start 2
	{
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	cudaDeviceSynchronize, 
	(
	);
	ld.param.b32	%r27, [retval0+0];
	}
	// Callseq End 2
	ret;
}

.visible .entry ao_ispc_tasks___sm35host(
	.param .u32 ao_ispc_tasks___sm35host_param_0,
	.param .u32 ao_ispc_tasks___sm35host_param_1,
	.param .u32 ao_ispc_tasks___sm35host_param_2,
	.param .u64 ao_ispc_tasks___sm35host_param_3
)
{
	.reg .pred 	%p<4>;
	.reg .s32 	%r<28>;
	.reg .s64 	%rd<13>;


	ld.param.u32 	%r4, [ao_ispc_tasks___sm35host_param_0];
	ld.param.u32 	%r5, [ao_ispc_tasks___sm35host_param_1];
	ld.param.u32 	%r6, [ao_ispc_tasks___sm35host_param_2];
	ld.param.u64 	%rd5, [ao_ispc_tasks___sm35host_param_3];
	add.s32 	%r7, %r4, 63;
	shr.s32 	%r8, %r7, 31;
	shr.u32 	%r9, %r8, 26;
	add.s32 	%r10, %r7, %r9;
	shr.s32 	%r1, %r10, 6;
	add.s32 	%r11, %r5, 3;
	shr.s32 	%r12, %r11, 31;
	shr.u32 	%r13, %r12, 30;
	add.s32 	%r14, %r11, %r13;
	shr.s32 	%r2, %r14, 2;
	mov.u32 	%r15, %tid.x;
	and.b32  	%r3, %r15, 31;
	setp.ne.s32	%p1, %r3, 0;
	mov.u64 	%rd12, 0;
	@%p1 bra 	BB3_3;

	mov.u64 	%rd7, 8;
	mov.u64 	%rd8, 24;
	// Callseq Start 3
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd8;
	.param .b64 retval0;
	call.uni (retval0), 
	cudaGetParameterBuffer, 
	(
	param0, 
	param1
	);
	ld.param.b64	%rd1, [retval0+0];
	}
	// Callseq End 3
	setp.eq.s64	%p2, %rd1, 0;
	mov.u64 	%rd12, %rd1;
	@%p2 bra 	BB3_3;

	st.u32 	[%rd1], %r4;
	st.u32 	[%rd1+4], %r5;
	st.u32 	[%rd1+8], %r6;
	st.u64 	[%rd1+16], %rd5;
	mov.u64 	%rd12, %rd1;

BB3_3:
	@%p1 bra 	BB3_5;

	add.s32 	%r24, %r1, -1;
	shr.s32 	%r25, %r24, 2;
	add.s32 	%r17, %r25, 1;
	mov.u32 	%r22, 1;
	mov.u32 	%r20, 128;
	mov.u32 	%r23, 0;
	mov.u64 	%rd11, 0;
	mov.u64 	%rd9, ao_task___UM_uniuniuniun_3C_unf_3E_;
	// inline asm
	{
     .param .b64 param0;
     st.param.b64	[param0+0], %rd9;
     .param .b64 param1;
     st.param.b64	[param1+0], %rd12;
     .param .align 4 .b8 param2[12];
     st.param.b32	[param2+0], %r17; 
     st.param.b32	[param2+4], %r2; 
     st.param.b32	[param2+8], %r22; 
     .param .align 4 .b8 param3[12];
     st.param.b32	[param3+0], %r20; 
     st.param.b32	[param3+4], %r22; 
     st.param.b32	[param3+8], %r22; 
     .param .b32 param4;
     st.param.b32	[param4+0], %r23; 
     .param .b64 param5;
     st.param.b64	[param5+0], %rd11; 

     .param .b32 retval0;
     call.uni (retval0), 
       cudaLaunchDevice,
       (
        param0, 
        param1, 
        param2, 
        param3, 
        param4, 
        param5
       );
     ld.param.b32	%r16, [retval0+0];
  }
  
	// inline asm

BB3_5:
	// Callseq Start 4
	{
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	cudaDeviceSynchronize, 
	(
	);
	ld.param.b32	%r26, [retval0+0];
	}
	// Callseq End 4
	// Callseq Start 5
	{
	.reg .b32 temp_param_reg;
	.param .b32 retval0;
	call.uni (retval0), 
	cudaDeviceSynchronize, 
	(
	);
	ld.param.b32	%r27, [retval0+0];
	}
	// Callseq End 5
	ret;
}



